{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import shap\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "\n",
    "\n",
    "PROJECT_DIR = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "SHAP_DIR = os.path.join(PROJECT_DIR, \"classification/shap_values/coqa\")\n",
    "SPLITS_DIR = os.path.join(PROJECT_DIR, \"classification/split_datasets/coqa\")\n",
    "MODELS_DIR = os.path.join(PROJECT_DIR, \"classification/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load SHAP values '''\n",
    "with open(os.path.join(SHAP_DIR, \"test.pkl\"), \"rb\") as f:\n",
    "    shap_values = pkl.load(f) # shape (1000, None, 2) (n_samples, n_features (not fixed), n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".values =\n",
       "array([[-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [-1.13922907e-04,  1.13922422e-04],\n",
       "       [ 9.92486351e-05, -9.92494096e-05],\n",
       "       [ 9.92486351e-05, -9.92494096e-05],\n",
       "       [ 9.92486351e-05, -9.92494096e-05],\n",
       "       [ 9.92486351e-05, -9.92494096e-05],\n",
       "       [ 9.92486351e-05, -9.92494096e-05],\n",
       "       [ 9.92486351e-05, -9.92494096e-05],\n",
       "       [ 9.92486351e-05, -9.92494096e-05],\n",
       "       [ 9.92486351e-05, -9.92494096e-05],\n",
       "       [ 9.92486351e-05, -9.92494096e-05],\n",
       "       [ 9.92486351e-05, -9.92494096e-05],\n",
       "       [-1.08400883e-05,  1.08405866e-05],\n",
       "       [-1.08400883e-05,  1.08405866e-05],\n",
       "       [-1.08400883e-05,  1.08405866e-05],\n",
       "       [-1.08400883e-05,  1.08405866e-05],\n",
       "       [-1.08400883e-05,  1.08405866e-05],\n",
       "       [-1.08400883e-05,  1.08405866e-05],\n",
       "       [ 9.78607518e-03, -9.78607483e-03],\n",
       "       [ 9.78607518e-03, -9.78607483e-03],\n",
       "       [ 9.78607518e-03, -9.78607483e-03],\n",
       "       [ 4.81447970e-03, -4.81447656e-03],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [-2.37636268e-05,  2.37638719e-05],\n",
       "       [ 1.18845426e-03, -1.18845455e-03],\n",
       "       [ 1.18845426e-03, -1.18845455e-03],\n",
       "       [ 1.18845426e-03, -1.18845455e-03],\n",
       "       [ 1.18845426e-03, -1.18845455e-03],\n",
       "       [ 1.18845426e-03, -1.18845455e-03],\n",
       "       [ 1.18845426e-03, -1.18845455e-03],\n",
       "       [ 1.18845426e-03, -1.18845455e-03],\n",
       "       [ 6.49327795e-04, -6.49328565e-04],\n",
       "       [ 6.49327795e-04, -6.49328565e-04],\n",
       "       [ 6.49327795e-04, -6.49328565e-04],\n",
       "       [ 6.49327795e-04, -6.49328565e-04],\n",
       "       [ 6.49327795e-04, -6.49328565e-04],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [-6.90484353e-05,  6.90483460e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 4.32925304e-05, -4.32922309e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 5.85827058e-05, -5.85825432e-05],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 1.26349434e-04, -1.26349246e-04],\n",
       "       [ 2.96900109e-03, -2.96900002e-03],\n",
       "       [ 2.96900109e-03, -2.96900002e-03],\n",
       "       [ 2.96900109e-03, -2.96900002e-03],\n",
       "       [ 2.96900109e-03, -2.96900002e-03],\n",
       "       [ 3.40475272e-03, -3.40475177e-03],\n",
       "       [ 1.57615627e-03, -1.57615556e-03],\n",
       "       [ 1.57615627e-03, -1.57615556e-03],\n",
       "       [ 1.57615627e-03, -1.57615556e-03],\n",
       "       [ 1.57615627e-03, -1.57615556e-03],\n",
       "       [ 3.23747771e-02, -3.23747773e-02],\n",
       "       [ 3.23747771e-02, -3.23747773e-02],\n",
       "       [ 1.02966818e-02, -1.02966832e-02],\n",
       "       [ 1.52507135e-01, -1.52507139e-01],\n",
       "       [ 5.50988707e-02, -5.50988718e-02],\n",
       "       [ 3.37680196e-02, -3.37680221e-02],\n",
       "       [ 9.01663546e-03, -9.01663633e-03],\n",
       "       [ 9.01663546e-03, -9.01663633e-03],\n",
       "       [ 2.73816064e-03, -2.73815965e-03],\n",
       "       [ 2.73816064e-03, -2.73815965e-03],\n",
       "       [ 2.35541972e-04, -2.35543117e-04],\n",
       "       [ 2.35541972e-04, -2.35543117e-04],\n",
       "       [ 2.35541972e-04, -2.35543117e-04],\n",
       "       [ 2.35541972e-04, -2.35543117e-04],\n",
       "       [ 2.35541972e-04, -2.35543117e-04],\n",
       "       [ 2.35541972e-04, -2.35543117e-04],\n",
       "       [ 3.32590884e-04, -3.32591037e-04],\n",
       "       [ 3.32590884e-04, -3.32591037e-04],\n",
       "       [ 3.32590884e-04, -3.32591037e-04],\n",
       "       [ 3.32590884e-04, -3.32591037e-04],\n",
       "       [ 3.32590884e-04, -3.32591037e-04],\n",
       "       [ 3.32590884e-04, -3.32591037e-04],\n",
       "       [ 3.32590884e-04, -3.32591037e-04],\n",
       "       [ 7.01013048e-04, -7.01013201e-04],\n",
       "       [ 7.01013048e-04, -7.01013201e-04],\n",
       "       [ 7.01013048e-04, -7.01013201e-04],\n",
       "       [ 7.01013048e-04, -7.01013201e-04],\n",
       "       [ 7.01013048e-04, -7.01013201e-04],\n",
       "       [ 7.01013048e-04, -7.01013201e-04],\n",
       "       [ 7.01013048e-04, -7.01013201e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04],\n",
       "       [ 1.53419234e-04, -1.53418766e-04]])\n",
       "\n",
       ".base_values =\n",
       "array([0.55925608, 0.44074392])\n",
       "\n",
       ".data =\n",
       "array(['', 'First', ', ', 'we ', 'know ', 'that ', 'Sam ', 'didn', \"'\",\n",
       "       't ', 'like ', 'the ', 'people ', 'he ', 'met ', 'while ',\n",
       "       'traveling', '. ', 'This ', 'means ', 'he ', 'wants ', 'to ',\n",
       "       'distance ', 'himself ', 'from ', 'them', '. \\n\\n', 'Option ', 'A',\n",
       "       ', ', 'coming ', 'home', ', ', 'is ', 'a ', 'possibility', '. ',\n",
       "       'If ', 'Sam ', 'is ', 'really ', 'unhappy ', 'with ', 'the ',\n",
       "       'people ', 'he', \"'\", 's ', 'met', ', ', 'he ', 'may ', 'decide ',\n",
       "       'to ', 'cut ', 'his ', 'trip ', 'short ', 'and ', 'return ',\n",
       "       'home', '. \\n\\n', 'Option ', 'B', ', ', 'taking ', 'an ',\n",
       "       'airplane', ', ', 'could ', 'also ', 'work', '. ', 'Sam ',\n",
       "       'could ', 'fly ', 'to ', 'a ', 'different ', 'location ', 'and ',\n",
       "       'start ', 'fresh ', 'with ', 'new ', 'people', '. \\n\\n', 'Option ',\n",
       "       'C', ', ', 'learning ', 'from ', 'each ', 'other', ', ', 'doesn',\n",
       "       \"'\", 't ', 'really ', 'address ', 'the ', 'issue ', 'of ', 'Sam ',\n",
       "       'not ', 'liking ', 'the ', 'people ', 'he', \"'\", 's ', 'met', '. ',\n",
       "       'It', \"'\", 's ', 'possible ', 'that ', 'he ', 'could ', 'learn ',\n",
       "       'something ', 'from ', 'them', ', ', 'but ', 'it ', 'doesn', \"'\",\n",
       "       't ', 'solve ', 'the ', 'problem ', 'of ', 'him ', 'wanting ',\n",
       "       'to ', 'get ', 'away ', 'from ', 'them', '. \\n\\n', 'Option ', 'D',\n",
       "       ', ', 'going ', 'out', ', ', 'could ', 'be ', 'a ', 'way ', 'for ',\n",
       "       'Sam ', 'to ', 'meet ', 'new ', 'people ', 'and ', 'potentially ',\n",
       "       'find ', 'some ', 'that ', 'he ', 'likes ', 'better', '. ',\n",
       "       'However', ', ', 'it ', 'doesn', \"'\", 't ', 'necessarily ',\n",
       "       'mean ', 'he', \"'\", 'll ', 'be ', 'able ', 'to ', 'completely ',\n",
       "       'distance ', 'himself ', 'from ', 'the ', 'people ', 'he ', 'didn',\n",
       "       \"'\", 't ', 'like', '. \\n\\n', 'Option ', 'E', ', ', 'making ',\n",
       "       'art', ', ', 'doesn', \"'\", 't ', 'really ', 'address ', 'the ',\n",
       "       'issue ', 'either', '. ', 'While ', 'it ', 'could ', 'be ', 'a ',\n",
       "       'way ', 'for ', 'Sam ', 'to ', 'express ', 'himself ', 'and ',\n",
       "       'potentially ', 'meet ', 'new ', 'people', ', ', 'it ', 'doesn',\n",
       "       \"'\", 't ', 'solve ', 'the ', 'problem ', 'of ', 'him ', 'not ',\n",
       "       'liking ', 'the ', 'people ', 'he', \"'\", 's ', 'currently ',\n",
       "       'with', '. \\n\\n', 'Based ', 'on ', 'these ', 'options', ', ',\n",
       "       'the ', 'best ', 'answer ', 'would ', 'be ', 'either ', 'A ',\n",
       "       'or ', 'B', ', ', 'depending ', 'on ', 'how ', 'much ', 'Sam ',\n",
       "       'wants ', 'to ', 'continue ', 'traveling', '. ', 'If ', 'he', \"'\",\n",
       "       's ', 'really ', 'unhappy', ', ', 'he ', 'may ', 'choose ', 'to ',\n",
       "       'come ', 'home', '. ', 'If ', 'he ', 'still ', 'wants ', 'to ',\n",
       "       'travel', ', ', 'he ', 'could ', 'take ', 'an ', 'airplane ',\n",
       "       'to ', 'a ', 'new ', 'location ', 'and ', 'start ', 'fresh', '.',\n",
       "       ''], dtype='<U12')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load data splits '''\n",
    "dataset = load_from_disk(os.path.join(SPLITS_DIR))\n",
    "texts = dataset[\"test\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = os.path.join(MODELS_DIR, \"distilbert-base-uncased_13091207\")\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(path_to_model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(path_to_model)\n",
    "model.to(device)\n",
    "\n",
    "pipe = TextClassificationPipeline(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    top_k=None, # get confidence scores for predictions\n",
    "    # `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
    ")\n",
    "pipe.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "samples = [\"I am in Finland\", \"seahorses are cool in Finland\"]\n",
    "explainer = shap.Explainer(pipe, seed=1)\n",
    "sample_shap_values = explainer(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".values =\n",
       "array([array([[ 0.        ,  0.        ],\n",
       "              [-0.05176722,  0.05176717],\n",
       "              [-0.0800604 ,  0.0800604 ],\n",
       "              [ 0.01499557, -0.01499558],\n",
       "              [-0.00300445,  0.00300446],\n",
       "              [ 0.        ,  0.        ]]),\n",
       "       array([[ 0.        ,  0.        ],\n",
       "              [ 0.03928477, -0.03928478],\n",
       "              [-0.03535185,  0.03535186],\n",
       "              [-0.05292681,  0.05292687],\n",
       "              [-0.02458153,  0.02458155],\n",
       "              [-0.06960601,  0.06960601],\n",
       "              [ 0.06535334, -0.06535332],\n",
       "              [-0.00453931,  0.0045393 ],\n",
       "              [ 0.        ,  0.        ]])], dtype=object)\n",
       "\n",
       ".base_values =\n",
       "array([[0.26197895, 0.73802108],\n",
       "       [0.25797108, 0.74202889]])\n",
       "\n",
       ".data =\n",
       "(array(['', 'I ', 'am ', 'in ', 'Finland', ''], dtype=object), array(['', 'sea', 'horse', 's ', 'are ', 'cool ', 'in ', 'Finland', ''],\n",
       "      dtype=object))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_1', 'score': 0.8578575253486633},\n",
       "  {'label': 'LABEL_0', 'score': 0.14214245975017548}],\n",
       " [{'label': 'LABEL_1', 'score': 0.8243963718414307},\n",
       "  {'label': 'LABEL_0', 'score': 0.17560367286205292}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams(tokens, n):\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "tokens = [t.strip().lower() for t in sample_shap_values.data[0]]\n",
    "bigrams = create_ngrams(tokens, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' i', 'i am', 'am in', 'in finland', 'finland ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' i': 1,\n",
       " 'i am': 1,\n",
       " 'am in': 1,\n",
       " 'in finland': 2,\n",
       " 'finland ': 2,\n",
       " ' sea': 1,\n",
       " 'sea horse': 1,\n",
       " 'horse s': 1,\n",
       " 's are': 1,\n",
       " 'are cool': 1,\n",
       " 'cool in': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_dict = {}\n",
    "n = 2\n",
    "\n",
    "for instance in sample_shap_values.data:\n",
    "    tokens = [token.strip().lower() for token in instance]\n",
    "    ngrams = create_ngrams(tokens, n)\n",
    "    \n",
    "    for ngram in ngrams:            \n",
    "        if ngram not in ngrams_dict:\n",
    "            ngrams_dict[ngram] = 1\n",
    "        else:\n",
    "            ngrams_dict[ngram] += 1\n",
    "\n",
    "ngrams_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<BOS> i': {'neg': [], 'pos': [0.02588360756635666]},\n",
       " 'i am': {'neg': [], 'pos': [0.06591380666941404]},\n",
       " 'am in': {'neg': [], 'pos': [0.03253241255879402]},\n",
       " 'in finland': {'neg': [-0.005995559506118298, -0.03040701523423195],\n",
       "  'pos': []},\n",
       " 'finland <EOS>': {'neg': [],\n",
       "  'pos': [0.0015022270381450653, 0.0022696563974022865]},\n",
       " '<BOS> sea': {'neg': [-0.01964238379150629], 'pos': []},\n",
       " 'sea horse': {'neg': [-0.0019664596766233444], 'pos': []},\n",
       " 'horse s': {'neg': [], 'pos': [0.04413933027535677]},\n",
       " 's are': {'neg': [], 'pos': [0.03875417169183493]},\n",
       " 'are cool': {'neg': [], 'pos': [0.047093771398067474]},\n",
       " 'cool in': {'neg': [], 'pos': [0.002126334235072136]}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding shap values for ngrams\n",
    "\n",
    "ngrams_dict = {}\n",
    "n = 2\n",
    "\n",
    "for instance in sample_shap_values:\n",
    "    tokens = [token.strip().lower() for token in instance.data]\n",
    "    ngrams = create_ngrams(tokens, n) # [' i', 'i am', 'am in', 'in finland', 'finland ']\n",
    "    shap_values = instance.values\n",
    "\n",
    "    for ngram in ngrams:\n",
    "        ngram_tokens = ngram.split()\n",
    "        ngram_idxs = [tokens.index(token) for token in ngram_tokens]\n",
    "        if ngram.startswith(\" \"): # at the start of the text\n",
    "            ngram_tokens = [\"<BOS>\"] + ngram_tokens\n",
    "            ngram_idxs = [0] + ngram_idxs\n",
    "            ngram = \"<BOS>\" + ngram\n",
    "        if ngram.endswith(\" \"): # at the end of the text\n",
    "            ngram_tokens = ngram_tokens + [\"<EOS>\"]\n",
    "            ngram_idxs = ngram_idxs + [len(tokens)-1]\n",
    "            ngram = ngram + \"<EOS>\"\n",
    "        \n",
    "        # get shap values for ngram\n",
    "        ngram_shap_values = shap_values[ngram_idxs[0]:ngram_idxs[-1]+1]\n",
    "        ngram_shap_values = np.mean(ngram_shap_values, axis=0) # sum or mean?\n",
    "\n",
    "        if ngram not in ngrams_dict:\n",
    "            ngrams_dict[ngram] = {\n",
    "                'neg': [],\n",
    "                'pos': []\n",
    "            }\n",
    "        \n",
    "        contribution_to_0 = ngram_shap_values[0]\n",
    "        contribution_to_1 = ngram_shap_values[1]\n",
    "        abs_shap_value = abs(contribution_to_0)\n",
    "\n",
    "        if contribution_to_0 > contribution_to_1:\n",
    "            # ngram contributes to prediction of class 0 (negative class)\n",
    "            # => store negative contribution\n",
    "            contribution = -abs_shap_value\n",
    "            ngrams_dict[ngram]['neg'].append(contribution)\n",
    "        elif contribution_to_0 < contribution_to_1:\n",
    "            # ngram contributes to prediction of class 1 (positive class)\n",
    "            # => store positive contribution\n",
    "            contribution = abs_shap_value\n",
    "            ngrams_dict[ngram]['pos'].append(contribution)\n",
    "        else:\n",
    "            # ngram does not contribute to prediction of either class\n",
    "            pass\n",
    "    \n",
    "ngrams_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
