{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased'\n",
    "responses_file = \"responses/12091031_parsed_turbo_10000_eval.jsonl\" # 10000 instances\n",
    "\n",
    "balance_dataset = False\n",
    "# use a single gpu\n",
    "use_latest_solution = False # tmp solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export \"CUDA_VISIBLE_DEVICES\"=2 jupyter notebook\n",
    "!export \"CUDA_VISIBLE_DEVICES\"=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.29.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('mps') # use mac m1 gpu\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.set_seed(42)\n",
    "\n",
    "label_mapping = {'False': 0, 'True': 1}\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(model_name,\n",
    "                                          num_labels=len(label_mapping),\n",
    "                                          hidden_dropout_prob=0.3,\n",
    "                                          attention_probs_dropout_prob=0.3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=model_config)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "RESPONSES_DIR = os.path.join(PROJECT_DIR, 'responses')\n",
    "MODELS_DIR = os.path.join(PROJECT_DIR, 'classification/models')\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, 'classification/preds')\n",
    "LOGS_DIR = os.path.join(PROJECT_DIR, 'logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sanctions were a punishing blow, which mea...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sammy wants to go where the people are. This m...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First, if the choker is not in a jewelry box o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Maps and other highway and street GPS s...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The fox walked from the city into the forest, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>First, we can eliminate options A, C, and D as...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>First, we need to identify what kind of lawyer...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>James bought a new set of tire chains. Tire ch...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>The question states that the food item needs t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Ficus is a type of tree that can provide shade...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   eval\n",
       "0     The sanctions were a punishing blow, which mea...  False\n",
       "1     Sammy wants to go where the people are. This m...   True\n",
       "2     First, if the choker is not in a jewelry box o...  False\n",
       "3     Google Maps and other highway and street GPS s...   True\n",
       "4     The fox walked from the city into the forest, ...   True\n",
       "...                                                 ...    ...\n",
       "9995  First, we can eliminate options A, C, and D as...  False\n",
       "9996  First, we need to identify what kind of lawyer...   True\n",
       "9997  James bought a new set of tire chains. Tire ch...   True\n",
       "9998  The question states that the food item needs t...  False\n",
       "9999  Ficus is a type of tree that can provide shade...   True\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(responses_file):\n",
    "    responses_path = responses_file\n",
    "else:\n",
    "    responses_path = os.path.join(RESPONSES_DIR, responses_file)\n",
    "    if not os.path.isfile(responses_path):\n",
    "        responses_path = os.path.join(PROJECT_DIR, responses_file)\n",
    "\n",
    "# create df. do not add an index column\n",
    "data_df = pd.read_json(responses_path, lines=True).drop(columns=['idx', 'uuid', 'parsed'])\n",
    "data_df['eval'] = data_df['eval'].apply(lambda x: x['outcome'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balance dataset\n",
    "\n",
    "The original dataset is slightly unbalanced (60/40) with more True instance. Balance the dataset so that we have equal number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if balance_dataset:\n",
    "\n",
    "    true_instances_count = len(data_df[data_df['outcome'] == True])\n",
    "    false_instances_count = len(data_df[data_df['outcome'] == False])\n",
    "    print(f'True instances: {true_instances_count}, False instances: {false_instances_count}')\n",
    "\n",
    "    # create balanced dataset\n",
    "    # a subset of data_df, where we select only false_instances_count number of true instances, and shuffle the data instances\n",
    "    balanced_data_df = pd.concat([data_df[data_df['outcome'] == True].sample(false_instances_count, random_state=1), data_df[data_df['outcome'] == False]]).sample(frac=1, random_state=1)\n",
    "\n",
    "    print(f'Balanced dataset: {len(balanced_data_df)} instances.\\n\\tLength match? {len(balanced_data_df) == false_instances_count * 2}')\n",
    "    \n",
    "    data_df = balanced_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 2), (1000, 2), (1000, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, tmp = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "val, test = train_test_split(tmp, test_size=0.5, random_state=42)\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'eval', '__index_level_0__'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'eval', '__index_level_0__'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'eval', '__index_level_0__'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "raw_datasets = DatasetDict({'train': Dataset.from_pandas(train),\n",
    "                            'validation': Dataset.from_pandas(val), \n",
    "                            'test': Dataset.from_pandas(test)})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in raw_datasets.keys():\n",
    "    raw_datasets[key] = raw_datasets[key].rename_column(\"eval\", \"label\")\n",
    "    raw_datasets[key] = raw_datasets[key].rename_column(\"__index_level_0__\", \"pandas_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'When someone is learning about science, they are likely to become more educated about scientific concepts and principles. This can lead to excitement as they discover new ideas and understand how the world works. They may also conduct experiments to test their understanding and gain hands-on experience. Accidents are possible during experiments, but they are not a necessary or desirable outcome of learning about science. Loss of interest is also not a typical result of learning about science, as many people find the subject fascinating and engaging. Therefore, the best answer is E. become educated.',\n",
       " 'label': True,\n",
       " 'pandas_idx': 9254}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a02043aed2b4fb694520dbb838851bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040eef93fb924818bbe82f06b240ff07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee20e15bece41db96e76747747b4ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# before tokenization, so it doesn't include input_ids, attention_mask, etc.\n",
    "# need this for knowing which instances are in which split\n",
    "\n",
    "#raw_datasets.save_to_disk(os.path.join(PROJECT_DIR, 'classification/split_datasets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_mask(raw_data):\n",
    "\n",
    "    '''Tokenize\n",
    "    Normal padding: set padding='max_length' and max_length=int (default is 512)\n",
    "    Dynamic padding: set padding=False and (later in the Trainer) pass `data_collator=DataCollatorWithPadding(tokenizer)\n",
    "    result will be a dict with keys 'input_ids', 'attention_mask'\n",
    "    '''\n",
    "    result = tokenizer(raw_data[\"text\"],\n",
    "                       max_length=512,\n",
    "                       truncation=True,\n",
    "                       #padding='max_length'\n",
    "                       )\n",
    "\n",
    "    '''Add labels'''\n",
    "    if label_mapping is not None:\n",
    "        if \"label\" in raw_data:\n",
    "            result['labels'] = [label_mapping[str(label)] for label in raw_data[\"label\"]]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5 5 5\n",
      "[1, 1, 0, 1, 0]\n",
      "[9254, 1561, 1670, 6087, 6669]\n",
      "text    First, we need to consider the size of the not...\n",
      "eval                                                False\n",
      "Name: 545, dtype: object\n"
     ]
    }
   ],
   "source": [
    "'''Sanity check'''\n",
    "\n",
    "processed_test = tokenize_and_mask(raw_datasets['train'][:5])\n",
    "\n",
    "print(len(processed_test), # keys\n",
    "      len(processed_test['input_ids']), \n",
    "      len(processed_test['attention_mask']), \n",
    "      len(processed_test['labels']))\n",
    "print(processed_test['labels'][:5])\n",
    "print(raw_datasets['train']['pandas_idx'][:5])\n",
    "print(data_df.loc[545])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a7d0786ccc4f62a76cfccc3ff5c27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12fb0b0eb75f46f48eb8e29cc447909e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb564b9af99475c94f894fe40b72408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Prepare inputs: tokenize and mask'''\n",
    "datasets = raw_datasets.map(tokenize_and_mask, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'pandas_idx', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'pandas_idx', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'pandas_idx', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    datasets[split].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 232])\n",
      "torch.Size([16, 328])\n",
      "torch.Size([16, 240])\n"
     ]
    }
   ],
   "source": [
    "from transformers import default_data_collator, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_collator_dynamic_padding = DataCollatorWithPadding(tokenizer,\n",
    "                                                        pad_to_multiple_of=8\n",
    "                                                        )\n",
    "\n",
    "train_dataloader = DataLoader(datasets['train'],\n",
    "                              batch_size=16,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=data_collator_dynamic_padding # default_data_collator or data_collator_dynamic_padding\n",
    "                              )\n",
    "\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    print(batch['input_ids'].shape)\n",
    "    if idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run on single GPU \n",
    "\n",
    "Discussion and possible solutions here:\n",
    "https://github.com/huggingface/transformers/issues/12570\n",
    "\n",
    "with latest version (transformers-4.34.0.dev0): \n",
    "AttributeError: 'customTrainingArguments' object has no attribute 'distributed_state' (for both solutions)\n",
    "\n",
    "downgrade to:\n",
    "pip install --upgrade transformers==4.29.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_latest_solution:\n",
    "\n",
    "    from transformers import TrainingArguments\n",
    "    from accelerate.state import AcceleratorState\n",
    "    from accelerate.utils import DistributedType\n",
    "\n",
    "    class cached_property(property):\n",
    "        def get(self, obj, objtype=None):\n",
    "            if obj is None:\n",
    "                return self\n",
    "\n",
    "            if self.fget is None:\n",
    "                raise AttributeError(\"unreadable attribute\")\n",
    "\n",
    "            attr = \"_cached\" + self.fget.name\n",
    "            cached = getattr(obj, attr, None)\n",
    "            if cached is None:\n",
    "                cached = self.fget(obj)\n",
    "                setattr(obj, attr, cached)\n",
    "                return cached\n",
    "                \n",
    "\n",
    "    class customTrainingArguments(TrainingArguments):\n",
    "        def __init__(self,*args, **kwargs):\n",
    "            super(customTrainingArguments, self).__init__(*args, **kwargs)\n",
    "\n",
    "        @property\n",
    "        def device(self) -> \"torch.device\":\n",
    "            return torch.device(\"cuda:1\")\n",
    "\n",
    "        @property\n",
    "        def n_gpu(self):\n",
    "            self._n_gpu = 1\n",
    "            return self._n_gpu\n",
    "\n",
    "        @property\n",
    "        def parallel_mode(self):\n",
    "            return \"not_parallel\"\n",
    "\n",
    "        @cached_property\n",
    "        def _setup_devices(self) -> \"torch.device\":\n",
    "            self.distributed_state = AcceleratorState(backend=self.ddp_backend)\n",
    "            self._n_gpu = 1\n",
    "            device = self.distributed_state.device\n",
    "            self.local_rank = self.distributed_state.local_process_index\n",
    "            self.distributed_state.distributed_type = DistributedType.NO\n",
    "            device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "            torch.cuda.set_device(device)\n",
    "            return device\n",
    "\n",
    "else:\n",
    "    class customTrainingArguments(TrainingArguments):\n",
    "        def __init__(self,*args, **kwargs):\n",
    "            super(customTrainingArguments, self).__init__(*args, **kwargs)\n",
    "\n",
    "        @property\n",
    "        #@torch_required\n",
    "        def device(self) -> \"torch.device\":\n",
    "            \"\"\"\n",
    "            The device used by this process.\n",
    "            Name the device the number you use.\n",
    "            \"\"\"\n",
    "            return torch.device(\"cuda:2\")\n",
    "\n",
    "        @property\n",
    "        #@torch_required\n",
    "        def n_gpu(self):\n",
    "            \"\"\"\n",
    "            The number of GPUs used by this process.\n",
    "            Note:\n",
    "                This will only be greater than one when you have multiple GPUs available but are not using distributed\n",
    "                training. For distributed training, it will always be 1.\n",
    "            \"\"\"\n",
    "            # Make sure `self._n_gpu` is properly setup.\n",
    "            # _ = self._setup_devices\n",
    "            # I set to one manullay\n",
    "            self._n_gpu = 1\n",
    "            return self._n_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training steps: 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/studenten-temp1/users/dpgo/xai-thesis/classification/finetune-venv/lib64/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, AdamW, get_cosine_schedule_with_warmup, EarlyStoppingCallback\n",
    "\n",
    "#training_args = TrainingArguments(\n",
    "training_args = customTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=0.0001,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.05,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_dir=LOGS_DIR,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=50,\n",
    "    load_best_model_at_end=True, # needed for early stopping\n",
    ")\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(), \n",
    "    lr=training_args.learning_rate,\n",
    "    betas=(0.9, 0.98),\n",
    "    eps=1e-6, # numerical stability\n",
    ")\n",
    "\n",
    "total_steps = len(datasets['train']) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "print(f\"Number of training steps: {total_steps}\")\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=training_args.warmup_steps, \n",
    "    num_training_steps=total_steps,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets['train'],\n",
    "    eval_dataset=datasets['validation'],\n",
    "    data_collator=data_collator_dynamic_padding, # default_data_collator or data_collator_dynamic_padding\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune + evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1050/2500 06:05 < 08:25, 2.87 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.667400</td>\n",
       "      <td>0.608188</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.785333</td>\n",
       "      <td>0.658837</td>\n",
       "      <td>0.971947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.543400</td>\n",
       "      <td>0.452147</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.858841</td>\n",
       "      <td>0.781081</td>\n",
       "      <td>0.953795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.487900</td>\n",
       "      <td>0.432837</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.862385</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.930693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.489300</td>\n",
       "      <td>0.452657</td>\n",
       "      <td>0.813000</td>\n",
       "      <td>0.863603</td>\n",
       "      <td>0.773856</td>\n",
       "      <td>0.976898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>0.466299</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>0.848528</td>\n",
       "      <td>0.750953</td>\n",
       "      <td>0.975248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.449857</td>\n",
       "      <td>0.813000</td>\n",
       "      <td>0.861993</td>\n",
       "      <td>0.779706</td>\n",
       "      <td>0.963696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.481600</td>\n",
       "      <td>0.460079</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.858232</td>\n",
       "      <td>0.797450</td>\n",
       "      <td>0.929043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.492989</td>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.855849</td>\n",
       "      <td>0.788595</td>\n",
       "      <td>0.935644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.452500</td>\n",
       "      <td>0.532040</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>0.842353</td>\n",
       "      <td>0.802691</td>\n",
       "      <td>0.886139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.485400</td>\n",
       "      <td>0.477318</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.849702</td>\n",
       "      <td>0.773713</td>\n",
       "      <td>0.942244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.431000</td>\n",
       "      <td>0.443011</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.862170</td>\n",
       "      <td>0.775726</td>\n",
       "      <td>0.970297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.478194</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.859940</td>\n",
       "      <td>0.790859</td>\n",
       "      <td>0.942244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.431500</td>\n",
       "      <td>0.487836</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.841767</td>\n",
       "      <td>0.820031</td>\n",
       "      <td>0.864686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.436600</td>\n",
       "      <td>0.474183</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.826645</td>\n",
       "      <td>0.804688</td>\n",
       "      <td>0.849835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.440700</td>\n",
       "      <td>0.454264</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.768831</td>\n",
       "      <td>0.976898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.344700</td>\n",
       "      <td>0.560643</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.860150</td>\n",
       "      <td>0.790055</td>\n",
       "      <td>0.943894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.384800</td>\n",
       "      <td>0.466823</td>\n",
       "      <td>0.807000</td>\n",
       "      <td>0.853677</td>\n",
       "      <td>0.789621</td>\n",
       "      <td>0.929043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.343400</td>\n",
       "      <td>0.548858</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.848576</td>\n",
       "      <td>0.777473</td>\n",
       "      <td>0.933993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>0.498312</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.849926</td>\n",
       "      <td>0.772973</td>\n",
       "      <td>0.943894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.338000</td>\n",
       "      <td>0.546511</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.808581</td>\n",
       "      <td>0.808581</td>\n",
       "      <td>0.808581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>0.765475</td>\n",
       "      <td>0.749000</td>\n",
       "      <td>0.781549</td>\n",
       "      <td>0.826888</td>\n",
       "      <td>0.740924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1050, training_loss=0.4381944020589193, metrics={'train_runtime': 366.6059, 'train_samples_per_second': 218.218, 'train_steps_per_second': 6.819, 'total_flos': 2344606722511872.0, 'train_loss': 0.4381944020589193, 'epoch': 4.2})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets['train']) // training_args.per_device_train_batch_size # steps per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.798, 'f1': 0.849702380952381, 'precision': 0.7737127371273713, 'recall': 0.9422442244224423}\n"
     ]
    }
   ],
   "source": [
    "# evaluate on val set - check that the loaded model is the intended one\n",
    "preds_val = trainer.predict(datasets['validation'])\n",
    "print(compute_metrics(preds_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.806, 'f1': 0.8600288600288599, 'precision': 0.7801047120418848, 'recall': 0.9581993569131833}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "preds_test = trainer.predict(datasets['test'])\n",
    "print(compute_metrics(preds_test))\n",
    "preds_test.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Save model'''\n",
    "import datetime\n",
    "model_id = datetime.datetime.now().strftime(\"%d%m%H%M\")\n",
    "#trainer.save_model(os.path.join(MODELS_DIR, f\"distilbert-base-uncased_{model_id}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
