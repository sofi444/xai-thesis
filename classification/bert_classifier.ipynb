{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased'\n",
    "responses_file = \"responses/04091703_parsed_turbo_2000train_clean_eval.jsonl\"\n",
    "balance_dataset = False\n",
    "use_latest_solution = False # run on single gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export \"CUDA_VISIBLE_DEVICES\"=1 jupyter notebook\n",
    "!export \"CUDA_VISIBLE_DEVICES\"=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.29.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('mps') # use mac m1 gpu\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {'False': 0, 'True': 1}\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(model_name,\n",
    "                                          num_labels=len(label_mapping),\n",
    "                                          hidden_dropout_prob=0.3,\n",
    "                                          attention_probs_dropout_prob=0.3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=model_config)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "RESPONSES_DIR = os.path.join(PROJECT_DIR, 'responses')\n",
    "MODELS_DIR = os.path.join(PROJECT_DIR, 'classification/models')\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, 'classification/preds')\n",
    "LOGS_DIR = os.path.join(PROJECT_DIR, 'logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sanctions were a punishing blow, which mea...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sammy wants to go where the people are. This m...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First, if the choker is not in a jewelry box o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Maps and other highway and street GPS s...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The fox walked from the city into the forest, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>First, we need to find a place with a dome. Th...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>The sentence mentions a \"baby bottle\" and \"pac...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>First, we need to determine what type of BBQ i...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>First, we need to understand what a disease is...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>First, we know that Joe was driven by curiosit...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   eval\n",
       "0     The sanctions were a punishing blow, which mea...  False\n",
       "1     Sammy wants to go where the people are. This m...   True\n",
       "2     First, if the choker is not in a jewelry box o...  False\n",
       "3     Google Maps and other highway and street GPS s...   True\n",
       "4     The fox walked from the city into the forest, ...   True\n",
       "...                                                 ...    ...\n",
       "1995  First, we need to find a place with a dome. Th...   True\n",
       "1996  The sentence mentions a \"baby bottle\" and \"pac...   True\n",
       "1997  First, we need to determine what type of BBQ i...  False\n",
       "1998  First, we need to understand what a disease is...   True\n",
       "1999  First, we know that Joe was driven by curiosit...  False\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(responses_file):\n",
    "    responses_path = responses_file\n",
    "else:\n",
    "    responses_path = os.path.join(RESPONSES_DIR, responses_file)\n",
    "    if not os.path.isfile(responses_path):\n",
    "        responses_path = os.path.join(PROJECT_DIR, responses_file)\n",
    "\n",
    "# create df. do not add an index column\n",
    "data_df = pd.read_json(responses_path, lines=True).drop(columns=['idx', 'uuid', 'parsed'])\n",
    "data_df['eval'] = data_df['eval'].apply(lambda x: x['outcome'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balance dataset\n",
    "\n",
    "The original dataset is slightly unbalanced (60/40) with more True instance. Balance the dataset so that we have equal number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if balance_dataset:\n",
    "\n",
    "    true_instances_count = len(data_df[data_df['outcome'] == True])\n",
    "    false_instances_count = len(data_df[data_df['outcome'] == False])\n",
    "    print(f'True instances: {true_instances_count}, False instances: {false_instances_count}')\n",
    "\n",
    "    # create balanced dataset\n",
    "    # a subset of data_df, where we select only false_instances_count number of true instances, and shuffle the data instances\n",
    "    balanced_data_df = pd.concat([data_df[data_df['outcome'] == True].sample(false_instances_count, random_state=1), data_df[data_df['outcome'] == False]]).sample(frac=1, random_state=1)\n",
    "\n",
    "    print(f'Balanced dataset: {len(balanced_data_df)} instances.\\n\\tLength match? {len(balanced_data_df) == false_instances_count * 2}')\n",
    "    \n",
    "    data_df = balanced_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600, 2), (200, 2), (200, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, tmp = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "val, test = train_test_split(tmp, test_size=0.5, random_state=42)\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'eval', '__index_level_0__'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'eval', '__index_level_0__'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'eval', '__index_level_0__'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "raw_datasets = DatasetDict({'train': Dataset.from_pandas(train),\n",
    "                            'validation': Dataset.from_pandas(val), \n",
    "                            'test': Dataset.from_pandas(test)})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in raw_datasets.keys():\n",
    "    raw_datasets[key] = raw_datasets[key].rename_column(\"eval\", \"label\")\n",
    "    raw_datasets[key] = raw_datasets[key].rename_column(\"__index_level_0__\", \"pandas_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The student left his writing instrument at his last place of study. This means that the instrument is not with him currently. \\n\\nOption A: Classroom - This could be a possibility if the student left the instrument on a desk or table in the classroom. \\n\\nOption B: Desk drawer - This could also be a possibility if the student had a desk or drawer in the classroom where he left the instrument. \\n\\nOption C: Bathroom - It is unlikely that the student left his writing instrument in the bathroom unless he was using it to write something while in there. \\n\\nOption D: Pocket - If the student had the instrument in his pocket, he would have realized that he still had it with him. \\n\\nOption E: Stationery store - This is not a possibility as the student left the instrument at his last place of study, not at a store. \\n\\nBased on the above analysis, options A and B seem to be the most likely possibilities. However, without more information, it is impossible to determine the exact location of the writing instrument.',\n",
       " 'label': False,\n",
       " 'pandas_idx': 968}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_mask(raw_data):\n",
    "\n",
    "    '''Tokenize\n",
    "    Normal padding: set padding='max_length' and max_length=int (default is 512)\n",
    "    Dynamic padding: set padding=False and (later in the Trainer) pass `data_collator=DataCollatorWithPadding(tokenizer)\n",
    "    result will be a dict with keys 'input_ids', 'attention_mask'\n",
    "    '''\n",
    "    result = tokenizer(raw_data[\"text\"],\n",
    "                       max_length=512,\n",
    "                       truncation=True,\n",
    "                       #padding='max_length'\n",
    "                       )\n",
    "\n",
    "    '''Add labels'''\n",
    "    if label_mapping is not None:\n",
    "        if \"label\" in raw_data:\n",
    "            result['labels'] = [label_mapping[str(label)] for label in raw_data[\"label\"]]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5 5 5\n",
      "[0, 0, 0, 1, 1]\n",
      "[968, 240, 819, 692, 420]\n",
      "text    First, we need to consider the size of the not...\n",
      "eval                                                 True\n",
      "Name: 545, dtype: object\n"
     ]
    }
   ],
   "source": [
    "'''Sanity check'''\n",
    "\n",
    "processed_test = tokenize_and_mask(raw_datasets['train'][:5])\n",
    "\n",
    "print(len(processed_test), # keys\n",
    "      len(processed_test['input_ids']), \n",
    "      len(processed_test['attention_mask']), \n",
    "      len(processed_test['labels']))\n",
    "print(processed_test['labels'][:5])\n",
    "print(raw_datasets['train']['pandas_idx'][:5])\n",
    "print(data_df.loc[545])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea320574b104161bd1265e85b3cd8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8db1ec8858748c680a0c1fc97a03658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3b4f720b294542b0481b7a8de7bbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Prepare inputs: tokenize and mask'''\n",
    "datasets = raw_datasets.map(tokenize_and_mask, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'pandas_idx', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'pandas_idx', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'pandas_idx', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    datasets[split].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 280])\n",
      "torch.Size([16, 216])\n",
      "torch.Size([16, 280])\n"
     ]
    }
   ],
   "source": [
    "from transformers import default_data_collator, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_collator_dynamic_padding = DataCollatorWithPadding(tokenizer,\n",
    "                                                        pad_to_multiple_of=8\n",
    "                                                        )\n",
    "\n",
    "train_dataloader = DataLoader(datasets['train'],\n",
    "                              batch_size=16,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=data_collator_dynamic_padding # default_data_collator or data_collator_dynamic_padding\n",
    "                              )\n",
    "\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    print(batch['input_ids'].shape)\n",
    "    if idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run on single GPU \n",
    "\n",
    "Discussion and possible solutions here:\n",
    "https://github.com/huggingface/transformers/issues/12570\n",
    "\n",
    "with latest version (transformers-4.34.0.dev0): \n",
    "AttributeError: 'customTrainingArguments' object has no attribute 'distributed_state' (for both solutions)\n",
    "\n",
    "downgrade to:\n",
    "pip install --upgrade transformers==4.29.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_latest_solution:\n",
    "\n",
    "    from transformers import TrainingArguments\n",
    "    from accelerate.state import AcceleratorState\n",
    "    from accelerate.utils import DistributedType\n",
    "\n",
    "    class cached_property(property):\n",
    "        def get(self, obj, objtype=None):\n",
    "            if obj is None:\n",
    "                return self\n",
    "\n",
    "            if self.fget is None:\n",
    "                raise AttributeError(\"unreadable attribute\")\n",
    "\n",
    "            attr = \"_cached\" + self.fget.name\n",
    "            cached = getattr(obj, attr, None)\n",
    "            if cached is None:\n",
    "                cached = self.fget(obj)\n",
    "                setattr(obj, attr, cached)\n",
    "                return cached\n",
    "                \n",
    "\n",
    "    class customTrainingArguments(TrainingArguments):\n",
    "        def __init__(self,*args, **kwargs):\n",
    "            super(customTrainingArguments, self).__init__(*args, **kwargs)\n",
    "\n",
    "        @property\n",
    "        def device(self) -> \"torch.device\":\n",
    "            return torch.device(\"cuda:1\")\n",
    "\n",
    "        @property\n",
    "        def n_gpu(self):\n",
    "            self._n_gpu = 1\n",
    "            return self._n_gpu\n",
    "\n",
    "        @property\n",
    "        def parallel_mode(self):\n",
    "            return \"not_parallel\"\n",
    "\n",
    "        @cached_property\n",
    "        def _setup_devices(self) -> \"torch.device\":\n",
    "            self.distributed_state = AcceleratorState(backend=self.ddp_backend)\n",
    "            self._n_gpu = 1\n",
    "            device = self.distributed_state.device\n",
    "            self.local_rank = self.distributed_state.local_process_index\n",
    "            self.distributed_state.distributed_type = DistributedType.NO\n",
    "            device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "            torch.cuda.set_device(device)\n",
    "            return device\n",
    "\n",
    "else:\n",
    "    class customTrainingArguments(TrainingArguments):\n",
    "        def __init__(self,*args, **kwargs):\n",
    "            super(customTrainingArguments, self).__init__(*args, **kwargs)\n",
    "\n",
    "        @property\n",
    "        #@torch_required\n",
    "        def device(self) -> \"torch.device\":\n",
    "            \"\"\"\n",
    "            The device used by this process.\n",
    "            Name the device the number you use.\n",
    "            \"\"\"\n",
    "            return torch.device(\"cuda:1\")\n",
    "\n",
    "        @property\n",
    "        #@torch_required\n",
    "        def n_gpu(self):\n",
    "            \"\"\"\n",
    "            The number of GPUs used by this process.\n",
    "            Note:\n",
    "                This will only be greater than one when you have multiple GPUs available but are not using distributed\n",
    "                training. For distributed training, it will always be 1.\n",
    "            \"\"\"\n",
    "            # Make sure `self._n_gpu` is properly setup.\n",
    "            # _ = self._setup_devices\n",
    "            # I set to one manullay\n",
    "            self._n_gpu = 1\n",
    "            return self._n_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training steps: 500\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, AdamW, get_cosine_schedule_with_warmup, EarlyStoppingCallback\n",
    "\n",
    "#training_args = TrainingArguments(\n",
    "training_args = customTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=0.0001,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.05,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_dir=LOGS_DIR,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=50,\n",
    "    load_best_model_at_end=True, # needed for early stopping\n",
    ")\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(), \n",
    "    lr=training_args.learning_rate,\n",
    "    betas=(0.9, 0.98),\n",
    "    eps=1e-6, # numerical stability\n",
    ")\n",
    "\n",
    "total_steps = len(datasets['train']) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "print(f\"Number of training steps: {total_steps}\")\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=training_args.warmup_steps, \n",
    "    num_training_steps=total_steps,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets['train'],\n",
    "    eval_dataset=datasets['validation'],\n",
    "    data_collator=data_collator_dynamic_padding, # default_data_collator or data_collator_dynamic_padding\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune + evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 02:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.668300</td>\n",
       "      <td>0.665066</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.757764</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.568779</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.819549</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.893443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.409100</td>\n",
       "      <td>0.638101</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.796992</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.868852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>0.686583</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.773663</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.770492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.240600</td>\n",
       "      <td>0.619478</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.751634</td>\n",
       "      <td>0.942623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.179500</td>\n",
       "      <td>0.683914</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.812261</td>\n",
       "      <td>0.762590</td>\n",
       "      <td>0.868852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>1.141810</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.763514</td>\n",
       "      <td>0.926230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>1.385006</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.885246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>1.603010</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.801556</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.653175</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.766917</td>\n",
       "      <td>0.836066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.24889229640364646, metrics={'train_runtime': 156.9334, 'train_samples_per_second': 101.954, 'train_steps_per_second': 3.186, 'total_flos': 1132066388914176.0, 'train_loss': 0.24889229640364646, 'epoch': 10.0})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.78, 'f1': 0.8333333333333333, 'precision': 0.7857142857142857, 'recall': 0.8870967741935484}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "preds_test = trainer.predict(datasets['test'])\n",
    "print(compute_metrics(preds_test))\n",
    "preds_test.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Save model'''\n",
    "import datetime\n",
    "model_id = datetime.datetime.now().strftime(\"%d%m%H%M\")\n",
    "#trainer.save_model(os.path.join(MODELS_DIR, f\"distilbert-base-uncased_{model_id}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
