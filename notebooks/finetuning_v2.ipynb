{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning v2\n",
    "\n",
    "Original attempt predicts all 1s. Improve.\n",
    "\n",
    "- balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export \"CUDA_VISIBLE_DEVICES\"=1 jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('mps')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(1)\n",
    "label_mapping = {'False': 0, 'True': 1}\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "model_config = AutoConfig.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=model_config)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "RESPONSES_DIR = os.path.join(PROJECT_DIR, 'responses')\n",
    "MODELS_DIR = os.path.join(PROJECT_DIR, 'classification/models')\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, 'classification/preds')\n",
    "LOGS_DIR = os.path.join(PROJECT_DIR, 'logs')\n",
    "\n",
    "responses_path = os.path.join(RESPONSES_DIR, 'formatted_turbo14081857_turbo1508_eval.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Revolving doors are convenient for two-directi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A) Completing the job is one aim that people h...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First, we need to identify what type of printe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- A fast food restaurant is a common place to ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First, James is looking for farmland, which su...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>First, we can eliminate options A, C, and D as...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>First, we need to identify what kind of lawyer...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>James bought a new set of tire chains. Tire ch...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>The question states that the food item needs t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>Ficus is a type of tree that can provide shade...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             full_text  outcome\n",
       "0    Revolving doors are convenient for two-directi...     True\n",
       "1    A) Completing the job is one aim that people h...    False\n",
       "2    First, we need to identify what type of printe...     True\n",
       "3    - A fast food restaurant is a common place to ...     True\n",
       "4    First, James is looking for farmland, which su...    False\n",
       "..                                                 ...      ...\n",
       "695  First, we can eliminate options A, C, and D as...    False\n",
       "696  First, we need to identify what kind of lawyer...     True\n",
       "697  James bought a new set of tire chains. Tire ch...     True\n",
       "698  The question states that the food item needs t...    False\n",
       "699  Ficus is a type of tree that can provide shade...     True\n",
       "\n",
       "[700 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_json(responses_path, orient='index').drop(columns=['answer_letter', 'answer_text', 'ERROR'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance dataset\n",
    "\n",
    "The original dataset is unbalanced (60/40) with more True instance. Balance the dataset so that we have equal number of instances. It will need more data to work well, but at least now it does not always predict 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True instances: 444, False instances: 256\n",
      "Balanced dataset: 512 instances.\n",
      "\tLength match? True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>First, we need to identify what kind of saw is...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>If fish are not in a stream, it means they are...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>First, we need to identify what \"pans\" are. Pa...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>First, it says \"most items in retail stores.\" ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>First, we need to understand what calorie requ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>John and Judy were parents, and they had two k...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>First, we need to identify what a container is...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>The Empire State Building is a landmark skyscr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>First, we need to understand what minerals are...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>If your date does not show up, the first thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             full_text  outcome\n",
       "399  First, we need to identify what kind of saw is...     True\n",
       "273  If fish are not in a stream, it means they are...    False\n",
       "80   First, we need to identify what \"pans\" are. Pa...    False\n",
       "386  First, it says \"most items in retail stores.\" ...     True\n",
       "679  First, we need to understand what calorie requ...    False\n",
       "..                                                 ...      ...\n",
       "651  John and Judy were parents, and they had two k...     True\n",
       "258  First, we need to identify what a container is...     True\n",
       "395  The Empire State Building is a landmark skyscr...    False\n",
       "238  First, we need to understand what minerals are...     True\n",
       "384  If your date does not show up, the first thing...     True\n",
       "\n",
       "[512 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_instances_count = len(data_df[data_df['outcome'] == True])\n",
    "false_instances_count = len(data_df[data_df['outcome'] == False])\n",
    "print(f'True instances: {true_instances_count}, False instances: {false_instances_count}')\n",
    "\n",
    "# create balanced dataset\n",
    "# a subset of data_df, where we select only false_instances_count number of true instances, and shuffle the data instances\n",
    "balanced_data_df = pd.concat([data_df[data_df['outcome'] == True].sample(false_instances_count, random_state=1), \n",
    "                              data_df[data_df['outcome'] == False]]).sample(frac=1, random_state=1)\n",
    "\n",
    "print(f'Balanced dataset: {len(balanced_data_df)} instances.\\n\\tLength match? {len(balanced_data_df) == false_instances_count * 2}')\n",
    "\n",
    "balanced_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((409, 2), (51, 2), (52, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = balanced_data_df\n",
    "\n",
    "train, tmp = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "val, test = train_test_split(tmp, test_size=0.5, random_state=42)\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['full_text', 'outcome', '__index_level_0__'],\n",
       "        num_rows: 409\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['full_text', 'outcome', '__index_level_0__'],\n",
       "        num_rows: 51\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['full_text', 'outcome', '__index_level_0__'],\n",
       "        num_rows: 52\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "raw_datasets = DatasetDict({'train': Dataset.from_pandas(train),\n",
    "                            'validation': Dataset.from_pandas(val), \n",
    "                            'test': Dataset.from_pandas(test)})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in raw_datasets.keys():\n",
    "    raw_datasets[key] = raw_datasets[key].rename_column(\"outcome\", \"label\")\n",
    "    raw_datasets[key] = raw_datasets[key].rename_column(\"__index_level_0__\", \"pandas_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_text': 'If chewing food is difficult for you, it could be because of a broken jaw or a sore mouth, which would make it painful to chew. It could also be because of difficulty with eating, such as missing teeth or a misaligned bite. However, good digestion would not affect the act of chewing itself, and avoiding choking would not necessarily make chewing difficult. Therefore, the possible reasons for difficulty in chewing food are A) broken jaw or B) sore mouth, making both choices correct.',\n",
       " 'label': False,\n",
       " 'pandas_idx': 166}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_mask(raw_data):\n",
    "\n",
    "    '''Tokenize\n",
    "    Normal padding: set padding='max_length' and max_length=int (default is 512)\n",
    "    Dynamic padding: set padding=False and (later in the Trainer) pass `data_collator=DataCollatorWithPadding(tokenizer)\n",
    "    result will be a dict with keys 'input_ids', 'attention_mask'\n",
    "    '''\n",
    "    result = tokenizer(raw_data[\"full_text\"],\n",
    "                       max_length=512,\n",
    "                       truncation=True,\n",
    "                       #padding='max_length'\n",
    "                       )\n",
    "\n",
    "    '''Add labels'''\n",
    "    if label_mapping is not None:\n",
    "        if \"label\" in raw_data:\n",
    "            result['labels'] = [label_mapping[str(label)] for label in raw_data[\"label\"]]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5 5 5\n",
      "[0, 1, 1, 0, 0]\n",
      "[166, 377, 448, 600, 305]\n",
      "full_text    Injecting water into oneself can lead to dilut...\n",
      "outcome                                                  False\n",
      "Name: 545, dtype: object\n"
     ]
    }
   ],
   "source": [
    "'''Sanity check'''\n",
    "\n",
    "processed_test = tokenize_and_mask(raw_datasets['train'][:5])\n",
    "\n",
    "print(len(processed_test), # keys\n",
    "      len(processed_test['input_ids']), \n",
    "      len(processed_test['attention_mask']), \n",
    "      len(processed_test['labels']))\n",
    "print(processed_test['labels'][:5])\n",
    "print(raw_datasets['train']['pandas_idx'][:5])\n",
    "print(data_df.loc[545])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e936f9050fe4a1085415b2788499cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f528f6f529154b4b856403ff068ecaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9afa27e32a447da0f9eec54f9bf0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Prepare inputs: tokenize and mask'''\n",
    "datasets = raw_datasets.map(tokenize_and_mask, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['full_text', 'label', 'pandas_idx', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 409\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['full_text', 'label', 'pandas_idx', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 51\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['full_text', 'label', 'pandas_idx', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 52\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    datasets[split].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 272])\n",
      "torch.Size([16, 248])\n",
      "torch.Size([16, 232])\n",
      "torch.Size([16, 208])\n",
      "torch.Size([16, 280])\n",
      "torch.Size([16, 312])\n"
     ]
    }
   ],
   "source": [
    "from transformers import default_data_collator, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_collator_dynamic_padding = DataCollatorWithPadding(tokenizer,\n",
    "                                                        pad_to_multiple_of=8\n",
    "                                                        )\n",
    "\n",
    "train_dataloader = DataLoader(datasets['train'],\n",
    "                              batch_size=16,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=data_collator_dynamic_padding # default_data_collator or data_collator_dynamic_padding\n",
    "                              )\n",
    "\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    print(batch['input_ids'].shape)\n",
    "    if idx == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from accelerate.state import AcceleratorState\n",
    "from accelerate.utils import DistributedType\n",
    "\n",
    "class cached_property(property):\n",
    "    def get(self, obj, objtype=None):\n",
    "        if obj is None:\n",
    "            return self\n",
    "\n",
    "        if self.fget is None:\n",
    "            raise AttributeError(\"unreadable attribute\")\n",
    "\n",
    "        attr = \"_cached\" + self.fget.name\n",
    "        cached = getattr(obj, attr, None)\n",
    "        if cached is None:\n",
    "            cached = self.fget(obj)\n",
    "            setattr(obj, attr, cached)\n",
    "            return cached\n",
    "            \n",
    "\n",
    "class customTrainingArguments(TrainingArguments):\n",
    "    def __init__(self,*args, **kwargs):\n",
    "        super(customTrainingArguments, self).__init__(*args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def device(self) -> \"torch.device\":\n",
    "        return torch.device(\"cuda:1\")\n",
    "\n",
    "    @property\n",
    "    def n_gpu(self):\n",
    "        self._n_gpu = 1\n",
    "        return self._n_gpu\n",
    "\n",
    "    @property\n",
    "    def parallel_mode(self):\n",
    "        return \"not_parallel\"\n",
    "\n",
    "    @cached_property\n",
    "    def _setup_devices(self) -> \"torch.device\":\n",
    "        self.distributed_state = AcceleratorState(backend=self.ddp_backend)\n",
    "        self._n_gpu = 1\n",
    "        device = self.distributed_state.device\n",
    "        self.local_rank = self.distributed_state.local_process_index\n",
    "        self.distributed_state.distributed_type = DistributedType.NO\n",
    "        device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "        torch.cuda.set_device(device)\n",
    "        return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training steps: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/studenten-temp1/users/dpgo/xai-thesis/thesis-venv/lib64/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AdamW, get_cosine_schedule_with_warmup\n",
    "\n",
    "#training_args = TrainingArguments(\n",
    "training_args = customTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=0.0001,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=LOGS_DIR,\n",
    "    logging_steps=10,\n",
    "    group_by_length=True,\n",
    ")\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(), \n",
    "    lr=training_args.learning_rate\n",
    ")\n",
    "\n",
    "total_steps = len(datasets['train']) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "print(f\"Number of training steps: {total_steps}\")\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=training_args.warmup_steps, \n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets['train'],\n",
    "    eval_dataset=datasets['validation'],\n",
    "    data_collator=data_collator_dynamic_padding, # default_data_collator or data_collator_dynamic_padding\n",
    "    optimizers=(optimizer, scheduler)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='208' max='208' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [208/208 00:09, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.391700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.361300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.264900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.351600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.371200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.334700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.170900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.063700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.156700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.205400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.073300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.247500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.412000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=208, training_loss=0.21534533519297838, metrics={'train_runtime': 9.4518, 'train_samples_per_second': 173.088, 'train_steps_per_second': 22.006, 'total_flos': 58072465688928.0, 'train_loss': 0.21534533519297838, 'epoch': 4.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/4 00:00 < 00:00, 25.86 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.5325576066970825,\n",
       " 'eval_runtime': 0.1576,\n",
       " 'eval_samples_per_second': 323.697,\n",
       " 'eval_steps_per_second': 25.388,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(datasets['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 0 0 1 0 1 1 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.7058823529411765}, {'f1': 0.7540983606557377})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "acc_metric = load_metric(\"accuracy\")\n",
    "f1_metric = load_metric(\"f1\")\n",
    "\n",
    "preds_val = trainer.predict(datasets['validation'])\n",
    "# preds_val.predictions is an array of arrays of logits\n",
    "\n",
    "def compute_metrics(model_preds):\n",
    "    gold_labels = model_preds.label_ids\n",
    "    logits = model_preds.predictions\n",
    "    preds = logits.argmax(-1)\n",
    "    print(preds)\n",
    "    \n",
    "    acc = acc_metric.compute(predictions=preds, references=gold_labels)\n",
    "    f1 = f1_metric.compute(predictions=preds, references=gold_labels)\n",
    "    \n",
    "    return acc, f1\n",
    "\n",
    "compute_metrics(preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/4 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1\n",
      " 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0]\n",
      "({'accuracy': 0.7115384615384616}, {'f1': 0.7692307692307692})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.4525049924850464,\n",
       " 'test_runtime': 0.166,\n",
       " 'test_samples_per_second': 313.168,\n",
       " 'test_steps_per_second': 24.09}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "preds_test = trainer.predict(datasets['test'])\n",
    "print(compute_metrics(preds_test))\n",
    "preds_test.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Save model'''\n",
    "import datetime\n",
    "model_id = datetime.datetime.now().strftime(\"%d%m%H%M\")\n",
    "#trainer.save_model(os.path.join(MODELS_DIR, f\"distilbert-base-uncased_{model_id}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
