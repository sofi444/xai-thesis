{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# Load transformer models\n",
    "\n",
    "# Get same splits to use with LR classifier\n",
    "# Get predictions from transformer models + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/studenten-temp1/users/dpgo/xai-thesis/thesis-venv/lib64/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "SPLITS_DIR = os.path.join(PROJECT_DIR, \"classification/split_datasets/coqa\")\n",
    "MODELS_DIR = os.path.join(PROJECT_DIR, \"classification/models\")\n",
    "\n",
    "models_paths_map = {\n",
    "    'distilbert': os.path.join(MODELS_DIR, \"distilbert-base-uncased_13091207\"),\n",
    "    'bert': os.path.join(MODELS_DIR, \"bert_14102004\"),\n",
    "    'bert-large': os.path.join(MODELS_DIR, \"bert-large_14101938\"),\n",
    "    'roberta': os.path.join(MODELS_DIR, \"roberta_14102014\"),\n",
    "    'deberta': os.path.join(MODELS_DIR, \"deberta_14102242\")\n",
    "}\n",
    "\n",
    "raw_dataset = load_from_disk(SPLITS_DIR)\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gold labels\n",
    "gold_labels = {\n",
    "    'validation': [0 if l==False else 1 for l in raw_dataset['validation']['label']],\n",
    "    'test': [0 if l==False else 1 for l in raw_dataset['test']['label']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pipe_and_predict(path_to_existing_model):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(path_to_existing_model)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(path_to_existing_model)\n",
    "    model.to(device)\n",
    "\n",
    "    pipe = pipeline(\"text-classification\",\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    #top_k=None, # get confidence scores for predictions\n",
    "    # `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
    "    )\n",
    "    pipe.device = device\n",
    "\n",
    "    val_preds = pipe(raw_dataset['validation']['text'])\n",
    "    test_preds = pipe(raw_dataset['test']['text'])\n",
    "    \n",
    "    preds = {\n",
    "        'validation': [\n",
    "            int(pred['label'].split('_')[-1]) for pred in val_preds\n",
    "        ],\n",
    "        'test': [\n",
    "            int(pred['label'].split('_')[-1]) for pred in test_preds\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_preds = init_pipe_and_predict(models_paths_map['distilbert'])\n",
    "bert_preds = init_pipe_and_predict(models_paths_map['bert'])\n",
    "bert_large_preds = init_pipe_and_predict(models_paths_map['bert-large'])\n",
    "roberta_preds = init_pipe_and_predict(models_paths_map['roberta'])\n",
    "deberta_preds = init_pipe_and_predict(models_paths_map['deberta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': [1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "          1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "          1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "          1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "          1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "          0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "          1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "          1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "          1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "          0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "          0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "          1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "          1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "          1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
      " 'validation': [1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "                1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "                1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "                1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "                1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "                1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "                1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "                0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "                1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "                1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "                0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "                1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "                0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "                1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "                0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(distilbert_preds, compact=True, width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3404\n",
      "{'label': False,\n",
      " 'pandas_idx': 2,\n",
      " 'text': 'First, if the choker is not in a jewelry box or boutique, it must be '\n",
      "         'somewhere else. So, we need to consider other possible locations. \\n'\n",
      "         '\\n'\n",
      "         'Some options could be:\\n'\n",
      "         '\\n'\n",
      "         '- Clothing stores: Some clothing stores may sell accessories like '\n",
      "         \"chokers, so it's worth checking out.\\n\"\n",
      "         '- Online marketplaces: You can search for chokers on online '\n",
      "         'marketplaces like Amazon, Etsy, or eBay.\\n'\n",
      "         '- Second-hand stores: You may be able to find a unique choker at a '\n",
      "         'second-hand store or thrift shop.\\n'\n",
      "         \"- Craft stores: If you're feeling creative, you can make your own \"\n",
      "         'choker by purchasing supplies at a craft store.\\n'\n",
      "         '\\n'\n",
      "         'So, the answer would be none of the above options listed in the '\n",
      "         'question.'}\n",
      "6521\n",
      "{'label': True,\n",
      " 'pandas_idx': 1,\n",
      " 'text': 'Sammy wants to go where the people are. This means he is looking for '\n",
      "         'a place where there are a lot of people. \\n'\n",
      "         '\\n'\n",
      "         'A. Race track - While there may be people at a race track, it is not '\n",
      "         'necessarily a place where a lot of people gather. \\n'\n",
      "         '\\n'\n",
      "         'B. Populated areas - This is a good option as populated areas are '\n",
      "         'places where a lot of people live and gather. \\n'\n",
      "         '\\n'\n",
      "         'C. The desert - This is not a good option as the desert is typically '\n",
      "         'a remote and uninhabited area. \\n'\n",
      "         '\\n'\n",
      "         'D. Apartment - This could be a good option as apartments are often '\n",
      "         'located in populated areas where there are a lot of people. \\n'\n",
      "         '\\n'\n",
      "         'E. Roadblock - This is not a good option as a roadblock is typically '\n",
      "         'a place where traffic is stopped and there may not be a lot of '\n",
      "         'people around. \\n'\n",
      "         '\\n'\n",
      "         'Therefore, the best answer is B. Populated areas.'}\n",
      "7171\n",
      "{'label': True,\n",
      " 'pandas_idx': 5,\n",
      " 'text': 'Home entertainment equipment typically includes devices such as '\n",
      "         'televisions, DVD/Blu-ray players, gaming consoles, and sound '\n",
      "         'systems. Out of these options, the only one that requires a cable is '\n",
      "         'a television. Therefore, the correct answer is D. television.'}\n",
      "7628\n",
      "{'label': True,\n",
      " 'pandas_idx': 4,\n",
      " 'text': 'The fox walked from the city into the forest, which suggests that it '\n",
      "         'was looking for a change of environment or habitat. Therefore, the '\n",
      "         'most likely answer is C. natural habitat. The other options, such as '\n",
      "         \"pretty flowers or a storybook, are unlikely to be the fox's \"\n",
      "         'motivation for leaving the city and entering the forest. The option '\n",
      "         'of a hen house is possible, but it is not the most likely answer as '\n",
      "         'the fox could have found food in the city as well. The option of a '\n",
      "         'dense forest is also possible, but it does not provide a clear '\n",
      "         \"reason for the fox's movement from the city.\"}\n",
      "574\n",
      "{'label': True,\n",
      " 'pandas_idx': 3,\n",
      " 'text': 'Google Maps and other highway and street GPS services provide '\n",
      "         'directions and maps for navigating roads and streets. Therefore, '\n",
      "         'they have replaced the need for physical maps, such as atlases, that '\n",
      "         'were previously used for the same purpose. \\n'\n",
      "         '\\n'\n",
      "         'So, the correct answer is D. atlas.'}\n",
      "857\n",
      "{'label': False,\n",
      " 'pandas_idx': 0,\n",
      " 'text': 'The sanctions were a punishing blow, which means they were severe '\n",
      "         'and had a negative impact on the school. The word \"seemed\" suggests '\n",
      "         'that the efforts the school had made to change were not recognized '\n",
      "         'or appreciated. Therefore, we can eliminate options A, D, and E, as '\n",
      "         'they do not fit the context. Option C, authoritarian, does not make '\n",
      "         'sense either, as it does not relate to the idea of sanctions or '\n",
      "         'efforts to change. The correct answer is B, enforce, as it implies '\n",
      "         'that the sanctions were implemented and had an impact on the '\n",
      "         \"school's efforts to improve.\"}\n"
     ]
    }
   ],
   "source": [
    "''' Sanity check: pandas_idx matches with order in responses-fe (and features file) '''\n",
    "for i, instance in enumerate(raw_dataset['train']):\n",
    "    if raw_dataset['train'][i]['pandas_idx'] <= 5:\n",
    "        print(i)\n",
    "        pp.pprint(instance, compact=True)\n",
    "for i, instance in enumerate(raw_dataset['test']):\n",
    "    if raw_dataset['test'][i]['pandas_idx'] <= 5:\n",
    "        print(i)\n",
    "        pp.pprint(instance, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_path = '/mount/studenten-temp1/users/dpgo/xai-thesis/responses/12091031_parsed_turbo_10000_eval.jsonl'\n",
    "features_all_path = '/mount/studenten-temp1/users/dpgo/xai-thesis/feature_extraction/12091031_all_features.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1   f2   f3  outcome\n",
       "0  0.1  0.2  0.3    False\n",
       "1  0.4  0.5  0.6     True\n",
       "2  0.7  0.8  0.9    False\n",
       "3  0.7  0.8  0.9    False\n",
       "4  0.7  0.8  0.9    False\n",
       "5  0.7  0.8  0.9    False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dummy df - data_df in lr_classifier.py\n",
    "df = pd.DataFrame(columns=['f1', 'f2', 'f3', 'outcome'])\n",
    "df.loc[0] = [0.1, 0.2, 0.3, False]\n",
    "df.loc[1] = [0.4, 0.5, 0.6, True]\n",
    "df.loc[2] = [0.7, 0.8, 0.9, False]\n",
    "df.loc[3] = [0.7, 0.8, 0.9, False]\n",
    "df.loc[4] = [0.7, 0.8, 0.9, False]\n",
    "df.loc[5] = [0.7, 0.8, 0.9, False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['train', 'validation', 'test'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy raw_dataset with only 2 instances per split\n",
    "from datasets import Dataset\n",
    "dummy_raw_dataset = Dataset.from_dict({\n",
    "    'train': [\n",
    "        {'pandas_idx': 0, 'label': False},\n",
    "        {'pandas_idx': 1, 'label': True},\n",
    "    ],\n",
    "    'validation': [\n",
    "        {'pandas_idx': 2, 'label': False},\n",
    "        {'pandas_idx': 3, 'label': False},\n",
    "    ],\n",
    "    'test': [\n",
    "        {'pandas_idx': 4, 'label': False},\n",
    "        {'pandas_idx': 5, 'label': False},\n",
    "    ]\n",
    "})\n",
    "dummy_raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_raw_dataset['train'][0]['pandas_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1   f2   f3  outcome\n",
       "0  0.1  0.2  0.3    False\n",
       "1  0.4  0.5  0.6     True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make train_df\n",
    "# it is a subset of data_df which only has the instances that are in the train split of dummy_raw_dataset\n",
    "\n",
    "# make list of pandas_idx in train split\n",
    "train_pandas_idx = [i['pandas_idx'] for i in dummy_raw_dataset['train']]\n",
    "\n",
    "# make train_df\n",
    "train_df = df[df.index.isin(train_pandas_idx)]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Dataset.to_pandas of Dataset({\n",
       "    features: ['text', 'label', 'pandas_idx'],\n",
       "    num_rows: 1000\n",
       "})>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['test'].to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pandas_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First, we need to identify the geographic feat...</td>\n",
       "      <td>True</td>\n",
       "      <td>4343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The question states that \"Everyone is ordinary...</td>\n",
       "      <td>True</td>\n",
       "      <td>1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First, we know that Sam didn't like the people...</td>\n",
       "      <td>False</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After falling, the person may feel pain or dis...</td>\n",
       "      <td>False</td>\n",
       "      <td>3383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When you travel with instruments, you need to ...</td>\n",
       "      <td>True</td>\n",
       "      <td>4534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>The juror was quite bored and zoning out but w...</td>\n",
       "      <td>False</td>\n",
       "      <td>9920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>First, the person was \"well ahead\" at the casi...</td>\n",
       "      <td>False</td>\n",
       "      <td>6123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>The sentence mentions that \"they were trying t...</td>\n",
       "      <td>True</td>\n",
       "      <td>7516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The windshield is a part of a vehicle that pro...</td>\n",
       "      <td>True</td>\n",
       "      <td>6746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>First, the child was jumping up and down on th...</td>\n",
       "      <td>True</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  pandas_idx\n",
       "0    First, we need to identify the geographic feat...   True        4343\n",
       "1    The question states that \"Everyone is ordinary...   True        1794\n",
       "2    First, we know that Sam didn't like the people...  False         708\n",
       "3    After falling, the person may feel pain or dis...  False        3383\n",
       "4    When you travel with instruments, you need to ...   True        4534\n",
       "..                                                 ...    ...         ...\n",
       "995  The juror was quite bored and zoning out but w...  False        9920\n",
       "996  First, the person was \"well ahead\" at the casi...  False        6123\n",
       "997  The sentence mentions that \"they were trying t...   True        7516\n",
       "998  The windshield is a part of a vehicle that pro...   True        6746\n",
       "999  First, the child was jumping up and down on th...   True        2908\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
