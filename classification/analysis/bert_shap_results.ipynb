{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregated SHAP values: understanding feature importances for finetuned BERT model\n",
    "\n",
    "SHAP values are assigned PER TOKEN PER INSTANCE (local explanation). By aggregating SHAP values across instances, we can get insights about which features (i.e., tokens) are important for the classification task (global explanation).\n",
    "\n",
    "\n",
    "Features == tokens\n",
    "\n",
    "\n",
    "3 types of aggregation:\n",
    "\n",
    "- at the token level: look at shap values of individual tokens across instances and average across occurrences of each token.\n",
    "\n",
    "- at the ngram level: look at ngrams across instances (any value of n). The SHAP value of an ngram is the sum of the SHAP values of its constituent tokens divided by n. Then, average across occurrences of each ngram.\n",
    "\n",
    "- at the chunk level: look at consecutive tokens that get the exact same SHAP values, treat them as a chunk whose SHAP values are the one of any of its constituent tokens (since they are all the same). Then, average across occurrences of each chunk.\n",
    "\n",
    "\n",
    "2 types of average:\n",
    "\n",
    "- per class: average contribution of a token WHEN IT DOES CONTRIBUTE to a class prediction (magnitude of contribution when it contributes)\n",
    "\n",
    "- overall: average contribution of a token across all instances where it appears, regardless of whether it contributes to the prediction or not (by averaging we can see whether on average it contributes more to pos/neg class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "PROJECT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "SHAP_DIR = os.path.join(PROJECT_DIR, 'classification/shap_values/coqa/')\n",
    "MASK_DIR = os.path.join(SHAP_DIR, 'masktoken_mask_default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "entity_frequency_dict = json.load(open(os.path.join(SHAP_DIR, 'bert_entity_frequency_test_empty.json'), 'r'))\n",
    "entity_frequency_dict_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def visualize_shap_results(shap_file, n_features=10, min_freq=20, min_chunk_size=1):\n",
    "\n",
    "    freq_dict = entity_frequency_dict\n",
    "    load_from_dir = SHAP_DIR\n",
    "    entity_type = shap_file.split('_')[3]+'s'\n",
    "\n",
    "    # Relevant for chunk-level shap values\n",
    "    # Using different mask token leads to different chunks\n",
    "    # + values derived with mask_token==[MASK] are in a different DIR\n",
    "    if 'mask' in shap_file:\n",
    "        freq_dict = entity_frequency_dict_mask\n",
    "        load_from_dir = MASK_DIR\n",
    "\n",
    "    if 'class-avg' in shap_file:\n",
    "        with open(os.path.join(load_from_dir, shap_file), 'r') as f:\n",
    "            shap_results = json.load(f)\n",
    "\n",
    "        # Filter out chunks with length < min_chunk_size\n",
    "        if entity_type == 'chunks':\n",
    "            shap_results = {\n",
    "                k: v for k, v in shap_results.items() if len(k.split(' ')) >= min_chunk_size\n",
    "            }\n",
    "\n",
    "        # Get frequency info and filter out entities with frequency < min_freq\n",
    "        sorted_neg = [\n",
    "            (k, v) for k, v in sorted(shap_results.items(), key=lambda item: item[1][0])\n",
    "            if freq_dict[entity_type][k] >= min_freq\n",
    "        ]\n",
    "        top_n_neg = sorted_neg[:n_features]\n",
    "        neg_df = pd.DataFrame(top_n_neg, columns=['entity', 'shap_values'])\n",
    "        neg_df['SV_neg_contribution'] = neg_df['shap_values'].apply(lambda x: float(x[0]))\n",
    "        neg_df['SV_pos_contribution'] = neg_df['shap_values'].apply(lambda x: float(x[1]))\n",
    "        neg_df = neg_df.drop(columns=['shap_values'])\n",
    "        \n",
    "        sorted_pos = [\n",
    "            (k, v) for k, v in sorted(shap_results.items(), key=lambda item: item[1][1])\n",
    "            if freq_dict[entity_type][k] >= min_freq\n",
    "        ]\n",
    "        top_n_pos = sorted_pos[-n_features:]\n",
    "        pos_df = pd.DataFrame(top_n_pos, columns=['entity', 'shap_values'])\n",
    "        pos_df['SV_neg_contribution'] = pos_df['shap_values'].apply(lambda x: float(x[0]))\n",
    "        pos_df['SV_pos_contribution'] = pos_df['shap_values'].apply(lambda x: float(x[1]))\n",
    "        pos_df = pos_df.drop(columns=['shap_values'])\n",
    "\n",
    "        top_shap_values = pd.merge(neg_df, pos_df, how='outer')\n",
    "\n",
    "        # add frequency info: add to name of entity\n",
    "        top_shap_values['entity'] = top_shap_values['entity'].apply(\n",
    "            lambda x: x + f\" ({freq_dict[entity_type][x]})\"\n",
    "        )\n",
    "\n",
    "        top_shap_values.plot(\n",
    "            x='entity', \n",
    "            y=['SV_neg_contribution', 'SV_pos_contribution'], \n",
    "            kind='barh', \n",
    "            figsize=(20, 15),\n",
    "            stacked=True\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        with open(os.path.join(load_from_dir, shap_file), 'r') as f:\n",
    "            shap_results = json.load(f)\n",
    "\n",
    "        # Filter out chunks with length < min_chunk_size\n",
    "        if entity_type == 'chunks':\n",
    "            shap_results = {\n",
    "                k: v for k, v in shap_results.items() if len(k.split(' ')) >= min_chunk_size\n",
    "            }\n",
    "        \n",
    "        sorted_shap_results = {\n",
    "            k: v for k, v in sorted(shap_results.items(), key=lambda item: item[1])\n",
    "        }\n",
    "        \n",
    "        shap_df = pd.DataFrame(sorted_shap_results.items(), columns=['entity', 'shap_value'])\n",
    "\n",
    "        # add frequency column\n",
    "        shap_df['frequency'] = shap_df['entity'].apply(\n",
    "            lambda x: freq_dict[entity_type][x]\n",
    "        )\n",
    "        # filter out entitys with frequency < min_freq\n",
    "        shap_df = shap_df[shap_df['frequency'] >= min_freq]\n",
    "\n",
    "        top_n_neg = shap_df.head(n_features)\n",
    "        top_n_pos = shap_df.tail(n_features)\n",
    "        top_shap_values = pd.merge(top_n_neg, top_n_pos, how='outer')\n",
    "\n",
    "        # add frequency to name of entity\n",
    "        top_shap_values['entity'] = top_shap_values['entity'].apply(\n",
    "            lambda x: x + f\" ({freq_dict[entity_type][x]})\"\n",
    "        )\n",
    "    \n",
    "        top_shap_values.plot(x='entity', y='shap_value', kind='barh', figsize=(20, 15))\n",
    "\n",
    "    return top_shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregations (global explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "top_tokens_overall = visualize_shap_results('agg-sv_bert_overall-avg_token_test.json', n_features=15, min_freq=20)\n",
    "#top_tokens_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per class avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "top_tokens_class = visualize_shap_results('agg-sv_bert_class-avg_token_test.json', n_features=15, min_freq=60)\n",
    "#top_tokens_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3gram-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "top_3grams_overall = visualize_shap_results('agg-sv_bert_overall-avg_3gram_test.json', n_features=15, min_freq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per class avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "top_3grams_class = visualize_shap_results('agg-sv_bert_class-avg_3gram_test.json', n_features=15, min_freq=40)\n",
    "#top_3grams_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5gram-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "top_5grams_overall = visualize_shap_results('agg-sv_bert_overall-avg_5gram_test.json', n_features=15, min_freq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per class avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "top_5grams_class = visualize_shap_results('agg-sv_bert_class-avg_5gram_test.json', n_features=15, min_freq=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunck-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "top_chunks_overall = visualize_shap_results('agg-sv_bert_overall-avg_chunk_test.json', n_features=15, min_freq=30)\n",
    "#top_chunks_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per class avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "top_chunks_class = visualize_shap_results('agg-sv_bert_class-avg_chunk_test.json', n_features=15, min_freq=40)\n",
    "#top_chunks_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'thesis-venv (Python 3.10.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "top_chunks2_class = visualize_shap_results('agg-sv_bert_class-avg_chunk_test.json', n_features=15, min_freq=5, min_chunk_size=3)\n",
    "#top_chunks2_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance-level (local explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
