{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers Agreement\n",
    "\n",
    "### How often do different classifiers make the same prediction?\n",
    "\n",
    "\n",
    "Classifiers:\n",
    "+ LR with trad features\n",
    "+ LR with all features\n",
    "+ LR with arg features\n",
    "+ DistilBERT\n",
    "+ BERT\n",
    "+ RoBERTa\n",
    "+ DeBERTa\n",
    "+ BERT-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers\n",
    "\n",
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "SPLITS_DIR = os.path.join(PROJECT_DIR, \"classification/split_datasets/coqa\")\n",
    "MODELS_DIR = os.path.join(PROJECT_DIR, \"classification/models\")\n",
    "\n",
    "models_paths_map = {\n",
    "    'distilbert': os.path.join(MODELS_DIR, \"distilbert-base-uncased_13091207\"),\n",
    "    'bert': os.path.join(MODELS_DIR, \"bert_14102004\"),\n",
    "    'bert-large': os.path.join(MODELS_DIR, \"bert-large_14101938\"),\n",
    "    'roberta': os.path.join(MODELS_DIR, \"roberta_14102014\"),\n",
    "    'deberta': os.path.join(MODELS_DIR, \"deberta_14102242\")\n",
    "}\n",
    "\n",
    "raw_dataset = load_from_disk(SPLITS_DIR)\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gold labels\n",
    "gold_labels = {\n",
    "    'validation': [0 if l==False else 1 for l in raw_dataset['validation']['label']],\n",
    "    'test': [0 if l==False else 1 for l in raw_dataset['test']['label']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'pandas_idx'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pipe_and_predict(path_to_existing_model):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(path_to_existing_model)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(path_to_existing_model)\n",
    "    model.to(device)\n",
    "\n",
    "    pipe = pipeline(\"text-classification\",\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        #top_k=None, # get confidence scores for predictions\n",
    "        # `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
    "    )\n",
    "    pipe.device = device\n",
    "\n",
    "    # Predict\n",
    "    # Sort raw_dataset by pandas_idx to get the same order of instances of in the LR predictions\n",
    "    val_preds = pipe(raw_dataset['test']['text'])\n",
    "    test_preds = pipe(raw_dataset['test']['text'])\n",
    "    \n",
    "    preds = {\n",
    "        'validation': [\n",
    "            int(pred['label'].split('_')[-1]) for pred in val_preds\n",
    "        ],\n",
    "        'test': [\n",
    "            int(pred['label'].split('_')[-1]) for pred in test_preds\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_preds = init_pipe_and_predict(models_paths_map['distilbert'])\n",
    "bert_preds = init_pipe_and_predict(models_paths_map['bert'])\n",
    "bert_large_preds = init_pipe_and_predict(models_paths_map['bert-large'])\n",
    "roberta_preds = init_pipe_and_predict(models_paths_map['roberta'])\n",
    "deberta_preds = init_pipe_and_predict(models_paths_map['deberta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      " 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      " 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      " 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      " 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      " 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      " 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      " 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      " 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      " 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      " 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      " 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      " 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      " 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      " 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      " 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      " 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      " 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      " 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      " 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      " 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      " 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      " 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      " 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      " 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(distilbert_preds['test'], compact=True, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3404\n",
      "{'label': False,\n",
      " 'pandas_idx': 2,\n",
      " 'text': 'First, if the choker is not in a jewelry box or boutique, it must be somewhere else. So, we need to consider '\n",
      "         'other possible locations. \\n'\n",
      "         '\\n'\n",
      "         'Some options could be:\\n'\n",
      "         '\\n'\n",
      "         \"- Clothing stores: Some clothing stores may sell accessories like chokers, so it's worth checking out.\\n\"\n",
      "         '- Online marketplaces: You can search for chokers on online marketplaces like Amazon, Etsy, or eBay.\\n'\n",
      "         '- Second-hand stores: You may be able to find a unique choker at a second-hand store or thrift shop.\\n'\n",
      "         \"- Craft stores: If you're feeling creative, you can make your own choker by purchasing supplies at a craft \"\n",
      "         'store.\\n'\n",
      "         '\\n'\n",
      "         'So, the answer would be none of the above options listed in the question.'}\n",
      "6521\n",
      "{'label': True,\n",
      " 'pandas_idx': 1,\n",
      " 'text': 'Sammy wants to go where the people are. This means he is looking for a place where there are a lot of '\n",
      "         'people. \\n'\n",
      "         '\\n'\n",
      "         'A. Race track - While there may be people at a race track, it is not necessarily a place where a lot of '\n",
      "         'people gather. \\n'\n",
      "         '\\n'\n",
      "         'B. Populated areas - This is a good option as populated areas are places where a lot of people live and '\n",
      "         'gather. \\n'\n",
      "         '\\n'\n",
      "         'C. The desert - This is not a good option as the desert is typically a remote and uninhabited area. \\n'\n",
      "         '\\n'\n",
      "         'D. Apartment - This could be a good option as apartments are often located in populated areas where there '\n",
      "         'are a lot of people. \\n'\n",
      "         '\\n'\n",
      "         'E. Roadblock - This is not a good option as a roadblock is typically a place where traffic is stopped and '\n",
      "         'there may not be a lot of people around. \\n'\n",
      "         '\\n'\n",
      "         'Therefore, the best answer is B. Populated areas.'}\n",
      "7171\n",
      "{'label': True,\n",
      " 'pandas_idx': 5,\n",
      " 'text': 'Home entertainment equipment typically includes devices such as televisions, DVD/Blu-ray players, gaming '\n",
      "         'consoles, and sound systems. Out of these options, the only one that requires a cable is a television. '\n",
      "         'Therefore, the correct answer is D. television.'}\n",
      "7628\n",
      "{'label': True,\n",
      " 'pandas_idx': 4,\n",
      " 'text': 'The fox walked from the city into the forest, which suggests that it was looking for a change of environment '\n",
      "         'or habitat. Therefore, the most likely answer is C. natural habitat. The other options, such as pretty '\n",
      "         \"flowers or a storybook, are unlikely to be the fox's motivation for leaving the city and entering the \"\n",
      "         'forest. The option of a hen house is possible, but it is not the most likely answer as the fox could have '\n",
      "         'found food in the city as well. The option of a dense forest is also possible, but it does not provide a '\n",
      "         \"clear reason for the fox's movement from the city.\"}\n",
      "574\n",
      "{'label': True,\n",
      " 'pandas_idx': 3,\n",
      " 'text': 'Google Maps and other highway and street GPS services provide directions and maps for navigating roads and '\n",
      "         'streets. Therefore, they have replaced the need for physical maps, such as atlases, that were previously '\n",
      "         'used for the same purpose. \\n'\n",
      "         '\\n'\n",
      "         'So, the correct answer is D. atlas.'}\n",
      "857\n",
      "{'label': False,\n",
      " 'pandas_idx': 0,\n",
      " 'text': 'The sanctions were a punishing blow, which means they were severe and had a negative impact on the school. '\n",
      "         'The word \"seemed\" suggests that the efforts the school had made to change were not recognized or '\n",
      "         'appreciated. Therefore, we can eliminate options A, D, and E, as they do not fit the context. Option C, '\n",
      "         'authoritarian, does not make sense either, as it does not relate to the idea of sanctions or efforts to '\n",
      "         'change. The correct answer is B, enforce, as it implies that the sanctions were implemented and had an '\n",
      "         \"impact on the school's efforts to improve.\"}\n"
     ]
    }
   ],
   "source": [
    "''' Sanity check: pandas_idx matches with order in responses-fe (and features file) '''\n",
    "for i, instance in enumerate(raw_dataset['train']):\n",
    "    if raw_dataset['train'][i]['pandas_idx'] <= 5:\n",
    "        print(i)\n",
    "        pp.pprint(instance, compact=True, width=120)\n",
    "for i, instance in enumerate(raw_dataset['test']):\n",
    "    if raw_dataset['test'][i]['pandas_idx'] <= 5:\n",
    "        print(i)\n",
    "        pp.pprint(instance, compact=True, width=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR\n",
    "\n",
    "Load predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDS_DIR = os.path.join(PROJECT_DIR, \"classification/preds\")\n",
    "\n",
    "'''\n",
    "arg: features from argument mining\n",
    "all: arg + traditional features\n",
    "col: select by removing collinear features\n",
    "kbest: select by kbest (chi2 test)\n",
    "rfe: select by recursive feature elimination\n",
    "'''\n",
    "\n",
    "preds_map = {\n",
    "    \"lr_arg\": os.path.join(PREDS_DIR, \"preds_12091031_all_arg.json\"),\n",
    "    \"lr_all-col-rfe\": os.path.join(PREDS_DIR, \"preds_12091031_col-rfe_all.json\"), # best accuracy\n",
    "    \"lr_all-rfe\": os.path.join(PREDS_DIR, \"preds_12091031_rfe_all.json\"),\n",
    "    \"lr_all_kbest-rfe\": os.path.join(PREDS_DIR, \"preds_12091031_kbest-rfe-ensemble_all.json\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def make_preds_comparable(lr_preds, dataset_split):\n",
    "    '''\n",
    "    LR predictions are sorted in ascending order of pandas_idx\n",
    "    and they come in a dict format: {pandas_idx: bool pred}\n",
    "\n",
    "    Change the order so that it is the same as the one in the dataset_split\n",
    "    (and matches the order of predictions of the transformer models)\n",
    "\n",
    "    Return a list of predictions as ints\n",
    "    '''\n",
    "    new_lr_preds = OrderedDict()\n",
    "    for instance in dataset_split:\n",
    "        idx = str(instance['pandas_idx'])\n",
    "        new_lr_preds[idx] = lr_preds[idx]\n",
    "\n",
    "    preds = []\n",
    "    for pred in new_lr_preds.values():\n",
    "        preds.append(int(pred))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds_arg = make_preds_comparable(json.load(open(preds_map[\"lr_arg\"])), raw_dataset['test'])\n",
    "\n",
    "lr_preds_all_col_rfe = make_preds_comparable(json.load(open(preds_map[\"lr_all-col-rfe\"])), raw_dataset['test'])\n",
    "lr_preds_all_rfe = make_preds_comparable(json.load(open(preds_map[\"lr_all-rfe\"])), raw_dataset['test'])\n",
    "lr_preds_all_kbest_rfe = make_preds_comparable(json.load(open(preds_map[\"lr_all_kbest-rfe\"])), raw_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: same number of instances in all lists\n",
    "len(lr_preds_all_col_rfe) == len(gold_labels['test']) == len(distilbert_preds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.722"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: same accuracy as in stats/\n",
    "# Proves that the order issue is fixed\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(lr_preds_all_col_rfe, gold_labels['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohen's Kappa\n",
    "\n",
    "It calculates the agreement between two raters who each classify N items into C mutually exclusive categories. The formula for Cohen's Kappa is:\n",
    "\n",
    "$$\\kappa = \\frac{p_o - p_e}{1 - p_e}$$\n",
    "\n",
    "where:\n",
    "- $p_o$ is the relative observed agreement among raters (identical to accuracy), and\n",
    "- $p_e$ is the hypothetical probability of chance agreement.\n",
    "\n",
    "\n",
    "Cohenâ€™s Kappa score ranges from -1 to +1.\n",
    "\n",
    "+ < 0: No agreement\n",
    "+ 0: Agreement equivalent to chance\n",
    "+ 0.01 - 0.20: Slight agreement\n",
    "+ 0.21 - 0.40: Fair agreement\n",
    "+ 0.41 - 0.60: Moderate agreement\n",
    "+ 0.61 - 0.80: Substantial agreement\n",
    "+ 0.81 - 1.00: Almost perfect agreement\n",
    "\n",
    "\n",
    "Cohen's Kappa has several advantages over accuracy when comparing two sets of predictions:\n",
    "\n",
    "1. **Accounting for chance**: Cohen's Kappa takes into account the possibility of the agreement occurring by chance. This is not the case with accuracy, which can give a misleadingly high score if one class is much more common than the other.\n",
    "\n",
    "2. **More robust for imbalanced classes**: If the classes in your dataset are imbalanced, accuracy can be misleading. For example, if 95% of your data is of class A, a model that always predicts A will have an accuracy of 95%, but it's not a good model. Cohen's Kappa is more robust in this situation.\n",
    "\n",
    "3. **Comparing different models**: Cohen's Kappa is especially useful when you want to compare the performance of different models or different runs of the same model. It gives you a measure of how consistently the models/runs are predicting.\n",
    "\n",
    "4. **Inter-rater reliability**: Cohen's Kappa is often used in situations where you want to measure inter-rater reliability, i.e., how much homogeneity or consensus exists in the ratings given by various judges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46819496076001654"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cohen_kappa_score(distilbert_preds['test'], lr_preds_all_col_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of pandas_idx on which the models agree/disagree\n",
    "instances_with_agreement = []\n",
    "instances_with_disagreement = []\n",
    "\n",
    "for i, instance in enumerate(raw_dataset['test']):\n",
    "    if distilbert_preds['test'][i] == lr_preds_all_col_rfe[i]:\n",
    "        instances_with_agreement.append(instance['pandas_idx'])\n",
    "    else:\n",
    "        instances_with_disagreement.append(instance['pandas_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794, 206)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instances_with_agreement), len(instances_with_disagreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agreement_stats(preds1, preds2, dataset_split):\n",
    "    '''\n",
    "    {\n",
    "    'distilbertxlr_all': {\n",
    "        'cohens_kappa': float,\n",
    "        'agreement': int, # len(instances_with_agreement)\n",
    "        'disagreement': int, # len(instances_with_disagreement)\n",
    "        'instances_with_agreement': list,\n",
    "        'instances_with_disagreement': list,\n",
    "        },\n",
    "    ...}\n",
    "    '''\n",
    "    agreement_stats = {\n",
    "        'cohens_kappa': round(cohen_kappa_score(preds1, preds2), 3),\n",
    "        'agreement': 0,\n",
    "        'disagreement': 0,\n",
    "        'accuracy_1': round(accuracy_score(preds1, gold_labels['test']), 3),\n",
    "        'accuracy_2': round(accuracy_score(preds2, gold_labels['test']), 3),\n",
    "        'instances_with_agreement': [],\n",
    "        'instances_with_disagreement': [],\n",
    "    }\n",
    "\n",
    "    for i, instance in enumerate(dataset_split):\n",
    "        if preds1[i] == preds2[i]:\n",
    "            agreement_stats['agreement'] += 1\n",
    "            agreement_stats['instances_with_agreement'].append(instance['pandas_idx'])\n",
    "        else:\n",
    "            agreement_stats['disagreement'] += 1\n",
    "            agreement_stats['instances_with_disagreement'].append(instance['pandas_idx'])\n",
    "\n",
    "    return agreement_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agreement stats for all pairs of models\n",
    "all_agreement_stats = {\n",
    "    \n",
    "    'transformerxlr': {\n",
    "        # all features\n",
    "        'distilbertxlr_all-col-rfe': get_agreement_stats(distilbert_preds['test'], lr_preds_all_col_rfe, raw_dataset['test']),\n",
    "        'distilbertxlr_all-rfe': get_agreement_stats(distilbert_preds['test'], lr_preds_all_rfe, raw_dataset['test']),\n",
    "        'distilbertxlr_all_kbest-rfe': get_agreement_stats(distilbert_preds['test'], lr_preds_all_kbest_rfe, raw_dataset['test']),\n",
    "\n",
    "        'bertxlr_all-col-rfe': get_agreement_stats(bert_preds['test'], lr_preds_all_col_rfe, raw_dataset['test']),\n",
    "        'bertxlr_all-rfe': get_agreement_stats(bert_preds['test'], lr_preds_all_rfe, raw_dataset['test']),\n",
    "        'bertxlr_all_kbest-rfe': get_agreement_stats(bert_preds['test'], lr_preds_all_kbest_rfe, raw_dataset['test']),\n",
    "\n",
    "        'bert-largexlr_all-col-rfe': get_agreement_stats(bert_large_preds['test'], lr_preds_all_col_rfe, raw_dataset['test']),\n",
    "        'bert-largexlr_all-rfe': get_agreement_stats(bert_large_preds['test'], lr_preds_all_rfe, raw_dataset['test']),\n",
    "        'bert-largexlr_all_kbest-rfe': get_agreement_stats(bert_large_preds['test'], lr_preds_all_kbest_rfe, raw_dataset['test']),\n",
    "\n",
    "        'robertaxlr_all-col-rfe': get_agreement_stats(roberta_preds['test'], lr_preds_all_col_rfe, raw_dataset['test']),\n",
    "        'robertaxlr_all-rfe': get_agreement_stats(roberta_preds['test'], lr_preds_all_rfe, raw_dataset['test']),\n",
    "        'robertaxlr_all_kbest-rfe': get_agreement_stats(roberta_preds['test'], lr_preds_all_kbest_rfe, raw_dataset['test']),\n",
    "\n",
    "        'debertaxlr_all-col-rfe': get_agreement_stats(deberta_preds['test'], lr_preds_all_col_rfe, raw_dataset['test']),\n",
    "        'debertaxlr_all-rfe': get_agreement_stats(deberta_preds['test'], lr_preds_all_rfe, raw_dataset['test']),\n",
    "        'debertaxlr_all_kbest-rfe': get_agreement_stats(deberta_preds['test'], lr_preds_all_kbest_rfe, raw_dataset['test']),\n",
    "\n",
    "        # arg features\n",
    "        'distilbertxlr_arg': get_agreement_stats(distilbert_preds['test'], lr_preds_arg, raw_dataset['test']),\n",
    "        'bertxlr_arg': get_agreement_stats(bert_preds['test'], lr_preds_arg, raw_dataset['test']),\n",
    "        'bert-largexlr_arg': get_agreement_stats(bert_large_preds['test'], lr_preds_arg, raw_dataset['test']),\n",
    "        'robertaxlr_arg': get_agreement_stats(roberta_preds['test'], lr_preds_arg, raw_dataset['test']),\n",
    "        'debertaxlr_arg': get_agreement_stats(deberta_preds['test'], lr_preds_arg, raw_dataset['test']),\n",
    "    },\n",
    "\n",
    "    'transformerxtransformer': {\n",
    "        'distilbertxbert': get_agreement_stats(distilbert_preds['test'], bert_preds['test'], raw_dataset['test']),\n",
    "        'distilbertxbert-large': get_agreement_stats(distilbert_preds['test'], bert_large_preds['test'], raw_dataset['test']),\n",
    "        'distilbertxroberta': get_agreement_stats(distilbert_preds['test'], roberta_preds['test'], raw_dataset['test']),\n",
    "        'distilbertxdeberta': get_agreement_stats(distilbert_preds['test'], deberta_preds['test'], raw_dataset['test']),\n",
    "        'bertxbert-large': get_agreement_stats(bert_preds['test'], bert_large_preds['test'], raw_dataset['test']),\n",
    "        'bertxroberta': get_agreement_stats(bert_preds['test'], roberta_preds['test'], raw_dataset['test']),\n",
    "        'bertxdeberta': get_agreement_stats(bert_preds['test'], deberta_preds['test'], raw_dataset['test']),\n",
    "        'bert-largexroberta': get_agreement_stats(bert_large_preds['test'], roberta_preds['test'], raw_dataset['test']),\n",
    "        'bert-largexdeberta': get_agreement_stats(bert_large_preds['test'], deberta_preds['test'], raw_dataset['test']),\n",
    "        'robertaxdeberta': get_agreement_stats(roberta_preds['test'], deberta_preds['test'], raw_dataset['test']),\n",
    "    },\n",
    "\n",
    "    'lrxlr': {\n",
    "        'lr_all-col-rfexlr_all-rfe': get_agreement_stats(lr_preds_all_col_rfe, lr_preds_all_rfe, raw_dataset['test']),\n",
    "        'lr_all-col-rfexlr_all_kbest-rfe': get_agreement_stats(lr_preds_all_col_rfe, lr_preds_all_kbest_rfe, raw_dataset['test']),\n",
    "        'lr_all-rfexlr_all_kbest-rfe': get_agreement_stats(lr_preds_all_rfe, lr_preds_all_kbest_rfe, raw_dataset['test']),\n",
    "        'lr_all-col-rfexlr_arg': get_agreement_stats(lr_preds_all_col_rfe, lr_preds_arg, raw_dataset['test']),\n",
    "        'lr_all-rfexlr_arg': get_agreement_stats(lr_preds_all_rfe, lr_preds_arg, raw_dataset['test']),\n",
    "        'lr_all_kbest-rfexlr_arg': get_agreement_stats(lr_preds_all_kbest_rfe, lr_preds_arg, raw_dataset['test']),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "ANALYSIS_DIR = os.path.join(PROJECT_DIR, \"classification/analysis\")\n",
    "\n",
    "with open(os.path.join(ANALYSIS_DIR, \"agreement_stats.json\"), 'w') as f:\n",
    "    json.dump(all_agreement_stats, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohens_kappa</th>\n",
       "      <th>agreement</th>\n",
       "      <th>disagreement</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distilbertxlr_all-rfe</th>\n",
       "      <td>0.471</td>\n",
       "      <td>785</td>\n",
       "      <td>215</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbertxlr_all-col-rfe</th>\n",
       "      <td>0.468</td>\n",
       "      <td>794</td>\n",
       "      <td>206</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debertaxlr_all-rfe</th>\n",
       "      <td>0.456</td>\n",
       "      <td>779</td>\n",
       "      <td>221</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debertaxlr_all-col-rfe</th>\n",
       "      <td>0.453</td>\n",
       "      <td>788</td>\n",
       "      <td>212</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertaxlr_all-rfe</th>\n",
       "      <td>0.440</td>\n",
       "      <td>772</td>\n",
       "      <td>228</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-largexlr_all-rfe</th>\n",
       "      <td>0.436</td>\n",
       "      <td>775</td>\n",
       "      <td>225</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-largexlr_all-col-rfe</th>\n",
       "      <td>0.435</td>\n",
       "      <td>786</td>\n",
       "      <td>214</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertxlr_all-rfe</th>\n",
       "      <td>0.435</td>\n",
       "      <td>773</td>\n",
       "      <td>227</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertxlr_all-col-rfe</th>\n",
       "      <td>0.429</td>\n",
       "      <td>782</td>\n",
       "      <td>218</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertaxlr_all-col-rfe</th>\n",
       "      <td>0.426</td>\n",
       "      <td>777</td>\n",
       "      <td>223</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbertxlr_all_kbest-rfe</th>\n",
       "      <td>0.415</td>\n",
       "      <td>767</td>\n",
       "      <td>233</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debertaxlr_all_kbest-rfe</th>\n",
       "      <td>0.395</td>\n",
       "      <td>759</td>\n",
       "      <td>241</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertxlr_all_kbest-rfe</th>\n",
       "      <td>0.382</td>\n",
       "      <td>757</td>\n",
       "      <td>243</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertaxlr_all_kbest-rfe</th>\n",
       "      <td>0.379</td>\n",
       "      <td>752</td>\n",
       "      <td>248</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-largexlr_all_kbest-rfe</th>\n",
       "      <td>0.377</td>\n",
       "      <td>757</td>\n",
       "      <td>243</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbertxlr_arg</th>\n",
       "      <td>0.248</td>\n",
       "      <td>744</td>\n",
       "      <td>256</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debertaxlr_arg</th>\n",
       "      <td>0.236</td>\n",
       "      <td>740</td>\n",
       "      <td>260</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertxlr_arg</th>\n",
       "      <td>0.219</td>\n",
       "      <td>740</td>\n",
       "      <td>260</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-largexlr_arg</th>\n",
       "      <td>0.213</td>\n",
       "      <td>742</td>\n",
       "      <td>258</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertaxlr_arg</th>\n",
       "      <td>0.202</td>\n",
       "      <td>727</td>\n",
       "      <td>273</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             cohens_kappa  agreement  disagreement  \\\n",
       "distilbertxlr_all-rfe               0.471        785           215   \n",
       "distilbertxlr_all-col-rfe           0.468        794           206   \n",
       "debertaxlr_all-rfe                  0.456        779           221   \n",
       "debertaxlr_all-col-rfe              0.453        788           212   \n",
       "robertaxlr_all-rfe                  0.440        772           228   \n",
       "bert-largexlr_all-rfe               0.436        775           225   \n",
       "bert-largexlr_all-col-rfe           0.435        786           214   \n",
       "bertxlr_all-rfe                     0.435        773           227   \n",
       "bertxlr_all-col-rfe                 0.429        782           218   \n",
       "robertaxlr_all-col-rfe              0.426        777           223   \n",
       "distilbertxlr_all_kbest-rfe         0.415        767           233   \n",
       "debertaxlr_all_kbest-rfe            0.395        759           241   \n",
       "bertxlr_all_kbest-rfe               0.382        757           243   \n",
       "robertaxlr_all_kbest-rfe            0.379        752           248   \n",
       "bert-largexlr_all_kbest-rfe         0.377        757           243   \n",
       "distilbertxlr_arg                   0.248        744           256   \n",
       "debertaxlr_arg                      0.236        740           260   \n",
       "bertxlr_arg                         0.219        740           260   \n",
       "bert-largexlr_arg                   0.213        742           258   \n",
       "robertaxlr_arg                      0.202        727           273   \n",
       "\n",
       "                             accuracy_1  accuracy_2  \n",
       "distilbertxlr_all-rfe             0.804       0.719  \n",
       "distilbertxlr_all-col-rfe         0.804       0.722  \n",
       "debertaxlr_all-rfe                0.810       0.719  \n",
       "debertaxlr_all-col-rfe            0.810       0.722  \n",
       "robertaxlr_all-rfe                0.813       0.719  \n",
       "bert-largexlr_all-rfe             0.814       0.719  \n",
       "bert-largexlr_all-col-rfe         0.814       0.722  \n",
       "bertxlr_all-rfe                   0.814       0.719  \n",
       "bertxlr_all-col-rfe               0.814       0.722  \n",
       "robertaxlr_all-col-rfe            0.813       0.722  \n",
       "distilbertxlr_all_kbest-rfe       0.804       0.695  \n",
       "debertaxlr_all_kbest-rfe          0.810       0.695  \n",
       "bertxlr_all_kbest-rfe             0.814       0.695  \n",
       "robertaxlr_all_kbest-rfe          0.813       0.695  \n",
       "bert-largexlr_all_kbest-rfe       0.814       0.695  \n",
       "distilbertxlr_arg                 0.804       0.630  \n",
       "debertaxlr_arg                    0.810       0.630  \n",
       "bertxlr_arg                       0.814       0.630  \n",
       "bert-largexlr_arg                 0.814       0.630  \n",
       "robertaxlr_arg                    0.813       0.630  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement_stats = json.load(open(os.path.join(ANALYSIS_DIR, \"agreement_stats.json\")))\n",
    "\n",
    "transformerxlr_agreement_df = pd.DataFrame.from_dict(\n",
    "    agreement_stats['transformerxlr'],\n",
    "    orient='index', \n",
    "    columns=['cohens_kappa', 'agreement', 'disagreement', 'accuracy_1', 'accuracy_2']\n",
    ")\n",
    "transformerxlr_agreement_df.sort_values(by=['cohens_kappa'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohens_kappa</th>\n",
       "      <th>agreement</th>\n",
       "      <th>disagreement</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertxbert-large</th>\n",
       "      <td>0.955</td>\n",
       "      <td>984</td>\n",
       "      <td>16</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertxdeberta</th>\n",
       "      <td>0.939</td>\n",
       "      <td>978</td>\n",
       "      <td>22</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-largexdeberta</th>\n",
       "      <td>0.933</td>\n",
       "      <td>976</td>\n",
       "      <td>24</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertaxdeberta</th>\n",
       "      <td>0.933</td>\n",
       "      <td>975</td>\n",
       "      <td>25</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertxroberta</th>\n",
       "      <td>0.931</td>\n",
       "      <td>975</td>\n",
       "      <td>25</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-largexroberta</th>\n",
       "      <td>0.931</td>\n",
       "      <td>975</td>\n",
       "      <td>25</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbertxbert-large</th>\n",
       "      <td>0.900</td>\n",
       "      <td>964</td>\n",
       "      <td>36</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbertxbert</th>\n",
       "      <td>0.890</td>\n",
       "      <td>960</td>\n",
       "      <td>40</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbertxdeberta</th>\n",
       "      <td>0.881</td>\n",
       "      <td>956</td>\n",
       "      <td>44</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbertxroberta</th>\n",
       "      <td>0.868</td>\n",
       "      <td>951</td>\n",
       "      <td>49</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cohens_kappa  agreement  disagreement  accuracy_1  \\\n",
       "bertxbert-large               0.955        984            16       0.814   \n",
       "bertxdeberta                  0.939        978            22       0.814   \n",
       "bert-largexdeberta            0.933        976            24       0.814   \n",
       "robertaxdeberta               0.933        975            25       0.813   \n",
       "bertxroberta                  0.931        975            25       0.814   \n",
       "bert-largexroberta            0.931        975            25       0.814   \n",
       "distilbertxbert-large         0.900        964            36       0.804   \n",
       "distilbertxbert               0.890        960            40       0.804   \n",
       "distilbertxdeberta            0.881        956            44       0.804   \n",
       "distilbertxroberta            0.868        951            49       0.804   \n",
       "\n",
       "                       accuracy_2  \n",
       "bertxbert-large             0.814  \n",
       "bertxdeberta                0.810  \n",
       "bert-largexdeberta          0.810  \n",
       "robertaxdeberta             0.810  \n",
       "bertxroberta                0.813  \n",
       "bert-largexroberta          0.813  \n",
       "distilbertxbert-large       0.814  \n",
       "distilbertxbert             0.814  \n",
       "distilbertxdeberta          0.810  \n",
       "distilbertxroberta          0.813  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformerxtransformer_agreement_df = pd.DataFrame.from_dict(\n",
    "    agreement_stats['transformerxtransformer'],\n",
    "    orient='index', \n",
    "    columns=['cohens_kappa', 'agreement', 'disagreement', 'accuracy_1', 'accuracy_2']\n",
    ")\n",
    "transformerxtransformer_agreement_df.sort_values(by=['cohens_kappa'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohens_kappa</th>\n",
       "      <th>agreement</th>\n",
       "      <th>disagreement</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr_all-col-rfexlr_all-rfe</th>\n",
       "      <td>0.735</td>\n",
       "      <td>889</td>\n",
       "      <td>111</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_all-rfexlr_all_kbest-rfe</th>\n",
       "      <td>0.719</td>\n",
       "      <td>880</td>\n",
       "      <td>120</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_all-col-rfexlr_all_kbest-rfe</th>\n",
       "      <td>0.682</td>\n",
       "      <td>869</td>\n",
       "      <td>131</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_all-col-rfexlr_arg</th>\n",
       "      <td>0.377</td>\n",
       "      <td>774</td>\n",
       "      <td>226</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_all_kbest-rfexlr_arg</th>\n",
       "      <td>0.364</td>\n",
       "      <td>761</td>\n",
       "      <td>239</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_all-rfexlr_arg</th>\n",
       "      <td>0.334</td>\n",
       "      <td>743</td>\n",
       "      <td>257</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 cohens_kappa  agreement  disagreement  \\\n",
       "lr_all-col-rfexlr_all-rfe               0.735        889           111   \n",
       "lr_all-rfexlr_all_kbest-rfe             0.719        880           120   \n",
       "lr_all-col-rfexlr_all_kbest-rfe         0.682        869           131   \n",
       "lr_all-col-rfexlr_arg                   0.377        774           226   \n",
       "lr_all_kbest-rfexlr_arg                 0.364        761           239   \n",
       "lr_all-rfexlr_arg                       0.334        743           257   \n",
       "\n",
       "                                 accuracy_1  accuracy_2  \n",
       "lr_all-col-rfexlr_all-rfe             0.722       0.719  \n",
       "lr_all-rfexlr_all_kbest-rfe           0.719       0.695  \n",
       "lr_all-col-rfexlr_all_kbest-rfe       0.722       0.695  \n",
       "lr_all-col-rfexlr_arg                 0.722       0.630  \n",
       "lr_all_kbest-rfexlr_arg               0.695       0.630  \n",
       "lr_all-rfexlr_arg                     0.719       0.630  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrxlr_agreement_df = pd.DataFrame.from_dict(\n",
    "    agreement_stats['lrxlr'],\n",
    "    orient='index', \n",
    "    columns=['cohens_kappa', 'agreement', 'disagreement', 'accuracy_1', 'accuracy_2']\n",
    ")\n",
    "lrxlr_agreement_df.sort_values(by=['cohens_kappa'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
